{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as ops\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import glog as log\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warning for tf 2.0\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Data Set and Weights Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = 'data/training_data_100/'\n",
    "# dataset_dir = 'data/training_data/'\n",
    "# dataset_dir = 'data/training_data_gamma_0d4/'\n",
    "dataset_dir = 'data/training_data_bdd100k/'\n",
    "\n",
    "# weights_path = None\n",
    "weights_path = 'model/tusimple_lanenet/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__C = edict()\n",
    "\n",
    "cfg = __C\n",
    "\n",
    "__C.TRAIN = edict()\n",
    "__C.TRAIN.EPOCHS = 10000\n",
    "__C.TRAIN.NOOFBATCHES = 10\n",
    "__C.TRAIN.MOMENTUM = 0.9\n",
    "__C.TRAIN.LEARNING_RATE = 0.0005\n",
    "__C.TRAIN.GPU_MEMORY_FRACTION = 0.85\n",
    "__C.TRAIN.TF_ALLOW_GROWTH = True\n",
    "__C.TRAIN.BATCH_SIZE = 8\n",
    "__C.TRAIN.IMG_HEIGHT = 256\n",
    "__C.TRAIN.IMG_WIDTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, dataset_info_file):\n",
    "        self._gt_img_list, self._gt_label_binary_list = self._init_dataset(dataset_info_file)\n",
    "        self._random_dataset()\n",
    "        self._next_batch_loop_count = 0\n",
    "\n",
    "    def _init_dataset(self, dataset_info_file):\n",
    "        gt_img_list = []\n",
    "        gt_label_binary_list = []\n",
    "\n",
    "        assert ops.exists(dataset_info_file), '{:s}ã€€does not exist'.format(dataset_info_file)\n",
    "\n",
    "        with open(dataset_info_file, 'r') as file:\n",
    "            for _info in file:\n",
    "                info_tmp = _info.strip(' ').split()\n",
    "\n",
    "                gt_img_list.append(info_tmp[0])\n",
    "                gt_label_binary_list.append(info_tmp[1])\n",
    "\n",
    "        return gt_img_list, gt_label_binary_list\n",
    "\n",
    "    def _random_dataset(self):\n",
    "        assert len(self._gt_img_list) == len(self._gt_label_binary_list)\n",
    "\n",
    "        random_idx = np.random.permutation(len(self._gt_img_list))\n",
    "        new_gt_img_list = []\n",
    "        new_gt_label_binary_list = []\n",
    "\n",
    "        for index in random_idx:\n",
    "            new_gt_img_list.append(self._gt_img_list[index])\n",
    "            new_gt_label_binary_list.append(self._gt_label_binary_list[index])\n",
    "\n",
    "        self._gt_img_list = new_gt_img_list\n",
    "        self._gt_label_binary_list = new_gt_label_binary_list\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        assert len(self._gt_label_binary_list) == len(self._gt_img_list)\n",
    "\n",
    "        idx_start = batch_size * self._next_batch_loop_count\n",
    "        idx_end = batch_size * self._next_batch_loop_count + batch_size\n",
    "\n",
    "        if idx_start == 0 and idx_end > len(self._gt_label_binary_list):\n",
    "            raise ValueError('Batch size cannot be larger than the total number of samples', \n",
    "                             idx_end, len(self._gt_label_binary_list))\n",
    "\n",
    "        if idx_end > len(self._gt_label_binary_list):\n",
    "            self._random_dataset()\n",
    "            self._next_batch_loop_count = 0\n",
    "            return self.next_batch(batch_size)\n",
    "        else:\n",
    "            gt_img_list = self._gt_img_list[idx_start:idx_end]\n",
    "            gt_label_binary_list = self._gt_label_binary_list[idx_start:idx_end]\n",
    "\n",
    "            gt_imgs = []\n",
    "            gt_labels_binary = []\n",
    "\n",
    "            for gt_img_path in gt_img_list:\n",
    "                gt_imgs.append(cv2.imread(gt_img_path, cv2.IMREAD_COLOR))\n",
    "\n",
    "            for gt_label_path in gt_label_binary_list:\n",
    "                label_img = cv2.imread(gt_label_path, cv2.IMREAD_COLOR)\n",
    "                label_binary = np.zeros([label_img.shape[0], label_img.shape[1]], dtype=np.uint8)\n",
    "                idx = np.where((label_img[:, :, :] != [0, 0, 0]).all(axis=2))\n",
    "                label_binary[idx] = 1\n",
    "                gt_labels_binary.append(label_binary)\n",
    "\n",
    "            self._next_batch_loop_count += 1\n",
    "\n",
    "        return gt_imgs, gt_labels_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_dataset_file = ops.join(dataset_dir, 'train.txt')\n",
    "assert ops.exists(train_dataset_file)\n",
    "train_dataset = DataSet(train_dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Base Function\n",
    "## cnn_basenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBaseModel(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def conv2d(inputdata, out_channel, kernel_size, padding='SAME',\n",
    "               stride=1, w_init=None, b_init=None,\n",
    "               split=1, use_bias=True, data_format='NHWC', name=None):\n",
    "        with tf.variable_scope(name):\n",
    "            in_shape = inputdata.get_shape().as_list()\n",
    "            channel_axis = 3 if data_format == 'NHWC' else 1\n",
    "            in_channel = in_shape[channel_axis]\n",
    "            assert in_channel is not None, \"[Conv2D] Input cannot have unknown channel!\"\n",
    "            assert in_channel % split == 0\n",
    "            assert out_channel % split == 0\n",
    "\n",
    "            padding = padding.upper()\n",
    "\n",
    "            if isinstance(kernel_size, list):\n",
    "                filter_shape = [kernel_size[0], kernel_size[1]] + [in_channel / split, out_channel]\n",
    "            else:\n",
    "                filter_shape = [kernel_size, kernel_size] + [in_channel / split, out_channel]\n",
    "\n",
    "            if isinstance(stride, list):\n",
    "                strides = [1, stride[0], stride[1], 1] if data_format == 'NHWC' \\\n",
    "                    else [1, 1, stride[0], stride[1]]\n",
    "            else:\n",
    "                strides = [1, stride, stride, 1] if data_format == 'NHWC' \\\n",
    "                    else [1, 1, stride, stride]\n",
    "\n",
    "            if w_init is None:\n",
    "                w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            if b_init is None:\n",
    "                b_init = tf.constant_initializer()\n",
    "\n",
    "            w = tf.get_variable('W', filter_shape, initializer=w_init)\n",
    "            b = None\n",
    "\n",
    "            if use_bias:\n",
    "                b = tf.get_variable('b', [out_channel], initializer=b_init)\n",
    "\n",
    "            if split == 1:\n",
    "                conv = tf.nn.conv2d(inputdata, w, strides, padding, data_format=data_format)\n",
    "            else:\n",
    "                inputs = tf.split(inputdata, split, channel_axis)\n",
    "                kernels = tf.split(w, split, 3)\n",
    "                outputs = [tf.nn.conv2d(i, k, strides, padding, data_format=data_format)\n",
    "                           for i, k in zip(inputs, kernels)]\n",
    "                conv = tf.concat(outputs, channel_axis)\n",
    "\n",
    "            ret = tf.identity(tf.nn.bias_add(conv, b, data_format=data_format) if use_bias else conv, name=name)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(inputdata, name=None):\n",
    "        return tf.nn.relu(features=inputdata, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def maxpooling(inputdata, kernel_size, stride=None, \\\n",
    "                   padding='VALID', data_format='NHWC', name=None):\n",
    "        padding = padding.upper()\n",
    "\n",
    "        if stride is None:\n",
    "            stride = kernel_size\n",
    "\n",
    "        if isinstance(kernel_size, list):\n",
    "            kernel = [1, kernel_size[0], kernel_size[1], 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, kernel_size[0], kernel_size[1]]\n",
    "        else:\n",
    "            kernel = [1, kernel_size, kernel_size, 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, kernel_size, kernel_size]\n",
    "\n",
    "        if isinstance(stride, list):\n",
    "            strides = [1, stride[0], stride[1], 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, stride[0], stride[1]]\n",
    "        else:\n",
    "            strides = [1, stride, stride, 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, stride, stride]\n",
    "\n",
    "        return tf.nn.max_pool(value=inputdata, ksize=kernel, strides=strides, \\\n",
    "                              padding=padding, data_format=data_format, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def layerbn(inputdata, is_training, name):\n",
    "        return tf.layers.batch_normalization(inputs=inputdata, training=is_training, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def deconv2d(inputdata, out_channel, kernel_size, padding='SAME',\n",
    "                 stride=1, w_init=None, b_init=None,\n",
    "                 use_bias=True, activation=None, data_format='channels_last',\n",
    "                 trainable=True, name=None):\n",
    "        with tf.variable_scope(name):\n",
    "            in_shape = inputdata.get_shape().as_list()\n",
    "            channel_axis = 3 if data_format == 'channels_last' else 1\n",
    "            in_channel = in_shape[channel_axis]\n",
    "            assert in_channel is not None, \"[Deconv2D] Input cannot have unknown channel!\"\n",
    "\n",
    "            padding = padding.upper()\n",
    "\n",
    "            if w_init is None:\n",
    "                w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            if b_init is None:\n",
    "                b_init = tf.constant_initializer()\n",
    "\n",
    "            ret = tf.layers.conv2d_transpose(inputs=inputdata, filters=out_channel,\n",
    "                                             kernel_size=kernel_size,\n",
    "                                             strides=stride, padding=padding,\n",
    "                                             data_format=data_format,\n",
    "                                             activation=activation, use_bias=use_bias,\n",
    "                                             kernel_initializer=w_init,\n",
    "                                             bias_initializer=b_init, trainable=trainable,\n",
    "                                             name=name)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model using conv2d, Relu and Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fcn_decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNDecoder(CNNBaseModel):\n",
    "    def __init__(self, phase):\n",
    "        super(FCNDecoder, self).__init__()\n",
    "\n",
    "    def decode(self, input_tensor_dict, decode_layer_list, name):\n",
    "        ret = dict()\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # score stage 1\n",
    "            input_tensor = input_tensor_dict[decode_layer_list[0]]['data']\n",
    "\n",
    "            score = self.conv2d(inputdata=input_tensor, out_channel=64,\n",
    "                                kernel_size=1, use_bias=False, name='score_origin')\n",
    "            decode_layer_list = decode_layer_list[1:]\n",
    "            for i in range(len(decode_layer_list)):\n",
    "                deconv = self.deconv2d(inputdata=score, out_channel=64, kernel_size=4,\n",
    "                                       stride=2, use_bias=False, name='deconv_{:d}'.format(i + 1))\n",
    "                input_tensor = input_tensor_dict[decode_layer_list[i]]['data']\n",
    "                score = self.conv2d(inputdata=input_tensor, out_channel=64,\n",
    "                                    kernel_size=1, use_bias=False, name='score_{:d}'.format(i + 1))\n",
    "                fused = tf.add(deconv, score, name='fuse_{:d}'.format(i + 1))\n",
    "                score = fused\n",
    "\n",
    "            deconv_final = self.deconv2d(inputdata=score, out_channel=64, kernel_size=16,\n",
    "                                         stride=8, use_bias=False, name='deconv_final')\n",
    "\n",
    "            score_final = self.conv2d(inputdata=deconv_final, out_channel=2,\n",
    "                                      kernel_size=1, use_bias=False, name='score_final')\n",
    "\n",
    "            ret['logits'] = score_final\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vgg_encoder.py\n",
    "https://github.com/machrisaa/tensorflow-vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Encoder(CNNBaseModel):\n",
    "    def __init__(self, phase):\n",
    "        super(VGG16Encoder, self).__init__()\n",
    "        self._train_phase = tf.constant('train', dtype=tf.string)\n",
    "        self._phase = phase\n",
    "        self._is_training = self._init_phase()\n",
    "\n",
    "    def _init_phase(self):\n",
    "        return tf.equal(self._phase, self._train_phase)\n",
    "\n",
    "    def _conv_stage(self, input_tensor, k_size, out_dims, name,\n",
    "                    stride=1, pad='SAME'):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = self.conv2d(inputdata=input_tensor, out_channel=out_dims,\n",
    "                               kernel_size=k_size, stride=stride,\n",
    "                               use_bias=False, padding=pad, name='conv')\n",
    "\n",
    "            bn = self.layerbn(inputdata=conv, is_training=self._is_training, name='bn')\n",
    "\n",
    "            relu = self.relu(inputdata=bn, name='relu')\n",
    "\n",
    "            return relu\n",
    "\n",
    "    def encode(self, input_tensor, name):\n",
    "        ret = OrderedDict()\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # conv stage 1\n",
    "            conv_1_1 = self._conv_stage(input_tensor=input_tensor, k_size=3, out_dims=64, name='conv1_1')\n",
    "            conv_1_2 = self._conv_stage(input_tensor=conv_1_1, k_size=3, out_dims=64, name='conv1_2')\n",
    "            pool1 = self.maxpooling(inputdata=conv_1_2, kernel_size=2, stride=2, name='pool1')\n",
    "\n",
    "            # conv stage 2\n",
    "            conv_2_1 = self._conv_stage(input_tensor=pool1, k_size=3, out_dims=128, name='conv2_1')\n",
    "            conv_2_2 = self._conv_stage(input_tensor=conv_2_1, k_size=3, out_dims=128, name='conv2_2')\n",
    "            pool2 = self.maxpooling(inputdata=conv_2_2, kernel_size=2, stride=2, name='pool2')\n",
    "\n",
    "            # conv stage 3\n",
    "            conv_3_1 = self._conv_stage(input_tensor=pool2, k_size=3, out_dims=256, name='conv3_1')\n",
    "            conv_3_2 = self._conv_stage(input_tensor=conv_3_1, k_size=3, out_dims=256, name='conv3_2')\n",
    "            conv_3_3 = self._conv_stage(input_tensor=conv_3_2, k_size=3, out_dims=256, name='conv3_3')\n",
    "            pool3 = self.maxpooling(inputdata=conv_3_3, kernel_size=2, stride=2, name='pool3')\n",
    "            ret['pool3'] = dict()\n",
    "            ret['pool3']['data'] = pool3\n",
    "            ret['pool3']['shape'] = pool3.get_shape().as_list()\n",
    "\n",
    "            # conv stage 4\n",
    "            conv_4_1 = self._conv_stage(input_tensor=pool3, k_size=3, out_dims=512, name='conv4_1')\n",
    "            conv_4_2 = self._conv_stage(input_tensor=conv_4_1, k_size=3, out_dims=512, name='conv4_2')\n",
    "            conv_4_3 = self._conv_stage(input_tensor=conv_4_2, k_size=3, out_dims=512, name='conv4_3')\n",
    "            pool4 = self.maxpooling(inputdata=conv_4_3, kernel_size=2, stride=2, name='pool4')\n",
    "            ret['pool4'] = dict()\n",
    "            ret['pool4']['data'] = pool4\n",
    "            ret['pool4']['shape'] = pool4.get_shape().as_list()\n",
    "\n",
    "            # conv stage 5\n",
    "            conv_5_1 = self._conv_stage(input_tensor=pool4, k_size=3, out_dims=512, name='conv5_1')\n",
    "            conv_5_2 = self._conv_stage(input_tensor=conv_5_1, k_size=3, out_dims=512, name='conv5_2')\n",
    "            conv_5_3 = self._conv_stage(input_tensor=conv_5_2, k_size=3, out_dims=512, name='conv5_3')\n",
    "            pool5 = self.maxpooling(inputdata=conv_5_3, kernel_size=2, stride=2, name='pool5')\n",
    "            ret['pool5'] = dict()\n",
    "            ret['pool5']['data'] = pool5\n",
    "            ret['pool5']['shape'] = pool5.get_shape().as_list()\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lanenet_merge_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneNet():\n",
    "    def __init__(self, phase):\n",
    "        super(LaneNet, self).__init__()\n",
    "        self._encoder = VGG16Encoder(phase=phase)\n",
    "        self._decoder = FCNDecoder(phase=phase)\n",
    "        return\n",
    "\n",
    "    def _build_model(self, input_tensor, name):\n",
    "        with tf.variable_scope(name):\n",
    "            # first encode\n",
    "            encode_ret = self._encoder.encode(input_tensor=input_tensor,\n",
    "                                              name='encode')\n",
    "            # second decode\n",
    "            decode_ret = self._decoder.decode(input_tensor_dict=encode_ret,\n",
    "                                              name='decode',\n",
    "                                              decode_layer_list=['pool5',\n",
    "                                                                 'pool4',\n",
    "                                                                 'pool3'])\n",
    "            return decode_ret\n",
    "\n",
    "    def compute_loss(self, input_tensor, binary_label, name):\n",
    "        with tf.variable_scope(name):\n",
    "            # Forward propagation to get logits\n",
    "            inference_ret = self._build_model(input_tensor=input_tensor, name='inference')\n",
    "\n",
    "            # Calculate the binary partition loss function\n",
    "            decode_logits = inference_ret['logits']\n",
    "            binary_label_plain = tf.reshape(binary_label,\n",
    "                                            shape=[binary_label.get_shape().as_list()[0] *\n",
    "                                                   binary_label.get_shape().as_list()[1] *\n",
    "                                                   binary_label.get_shape().as_list()[2]])\n",
    "            # Add class weights\n",
    "            unique_labels, unique_id, counts = tf.unique_with_counts(binary_label_plain)\n",
    "            counts = tf.cast(counts, tf.float32)\n",
    "            inverse_weights = tf.divide(1.0,\n",
    "                                        tf.log(tf.add(tf.divide(tf.constant(1.0), counts),\n",
    "                                                      tf.constant(1.02))))\n",
    "            inverse_weights = tf.gather(inverse_weights, binary_label)\n",
    "            binary_segmenatation_loss = tf.losses.sparse_softmax_cross_entropy(labels=binary_label, \\\n",
    "                                                                               logits=decode_logits, \\\n",
    "                                                                               weights=inverse_weights)\n",
    "            binary_segmenatation_loss = tf.reduce_mean(binary_segmenatation_loss)\n",
    "\n",
    "            ret = {'loss': binary_segmenatation_loss, 'binary_seg_logits': decode_logits}\n",
    "\n",
    "            return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cost, optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    input_tensor = tf.placeholder(dtype=tf.float32,\n",
    "                                  shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                         CFG.TRAIN.IMG_WIDTH, 3],\n",
    "                                  name='input_tensor')\n",
    "    binary_label = tf.placeholder(dtype=tf.int64,\n",
    "                                  shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                         CFG.TRAIN.IMG_WIDTH, 1],\n",
    "                                         name='binary_label')\n",
    "\n",
    "    # Create the model\n",
    "    phase = tf.placeholder(dtype=tf.string, shape=None, name='net_phase')\n",
    "    net = LaneNet(phase=phase)\n",
    "\n",
    "    # Define loss\n",
    "    compute_ret = net.compute_loss(input_tensor=input_tensor, binary_label=binary_label, name='lanenet_model')\n",
    "    loss = compute_ret['loss']\n",
    "\n",
    "    # Evaluate model\n",
    "    out_logits = compute_ret['binary_seg_logits']\n",
    "    out_logits = tf.nn.softmax(logits=out_logits)\n",
    "    out_logits_out = tf.argmax(out_logits, axis=-1)\n",
    "    out = tf.argmax(out_logits, axis=-1)\n",
    "    out = tf.expand_dims(out, axis=-1)\n",
    "\n",
    "    idx = tf.where(tf.equal(binary_label, 1))\n",
    "    pix_cls_ret = tf.gather_nd(out, idx)\n",
    "    accuracy = tf.count_nonzero(pix_cls_ret)\n",
    "    accuracy = tf.divide(accuracy, tf.cast(tf.shape(pix_cls_ret)[0], tf.int64))\n",
    "\n",
    "    # Define optimizer\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(CFG.TRAIN.LEARNING_RATE, global_step,\n",
    "                                               100000, 0.1, staircase=True)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \\\n",
    "                                               momentum=CFG.TRAIN.MOMENTUM).minimize(loss=loss,\n",
    "                                                                                     var_list=tf.trainable_variables(),\n",
    "                                                                                     global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sess configuration\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TRAIN.GPU_MEMORY_FRACTION\n",
    "sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "sess = tf.Session(config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/tusimple_lanenet/lanenet_model.pb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set tf saver\n",
    "model_save_dir = 'model/tusimple_lanenet'\n",
    "if not ops.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "\n",
    "train_start_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "model_name = 'tusimple_lanenet_{:s}.ckpt'.format(str(train_start_time))\n",
    "model_save_path = ops.join(model_save_dir, model_name)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "tf.train.write_graph(graph_or_graph_def=sess.graph, logdir='',\n",
    "                     name='{:s}/lanenet_model.pb'.format(model_save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tf summary\n",
    "tboard_save_path = 'tboard/tusimple_lanenet_{:s}'.format(str(train_start_time))\n",
    "if not ops.exists(tboard_save_path):\n",
    "    os.makedirs(tboard_save_path)\n",
    "\n",
    "train_accuracy_scalar = tf.summary.scalar(name='train_accuracy', tensor=accuracy)\n",
    "train_loss_scalar = tf.summary.scalar(name='train_loss', tensor=loss)\n",
    "learning_rate_scalar = tf.summary.scalar(name='learning_rate', tensor=learning_rate)\n",
    "merged_summary_op = tf.summary.merge([train_accuracy_scalar, train_loss_scalar, learning_rate_scalar])\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(tboard_save_path)\n",
    "summary_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output image folder\n",
    "image_save_path = 'data_ret/tusimple_lanenet_{:s}'.format(str(train_start_time))\n",
    "if not ops.exists(image_save_path):\n",
    "    os.makedirs(image_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "history = []\n",
    "train_cost_time_mean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_training_data(gt_imgs, binary_gt_labels):\n",
    "    gt_imgs = [cv2.resize(tmp,\n",
    "                          dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "                          dst=tmp,\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "               for tmp in gt_imgs]\n",
    "    gt_imgs = [tmp - VGG_MEAN for tmp in gt_imgs]\n",
    "\n",
    "    binary_gt_labels = [cv2.resize(tmp,\n",
    "                                   dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "                                   dst=tmp,\n",
    "                                   interpolation=cv2.INTER_NEAREST)\n",
    "                        for tmp in binary_gt_labels]\n",
    "    binary_gt_labels = [np.expand_dims(tmp, axis=-1) for tmp in binary_gt_labels]\n",
    "    \n",
    "    return gt_imgs, binary_gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0328 00:18:13.049022 6137 <ipython-input-20-f0cae5ef1aeb>:19] Restore model from last model checkpoint model/tusimple_lanenet/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0 loss= 107.451225 acc= 0.116021 cost_time= 0.426230s \n",
      "Epoch:     10 loss= 14.476472 acc= 0.378753 cost_time= 0.295058s \n",
      "Epoch:     20 loss= 10.874406 acc= 0.288877 cost_time= 0.295723s \n",
      "Epoch:     30 loss= 7.590229 acc= 0.367887 cost_time= 0.296614s \n",
      "Epoch:     40 loss= 7.134631 acc= 0.268983 cost_time= 0.293991s \n",
      "Epoch:     50 loss= 7.949111 acc= 0.272148 cost_time= 0.295835s \n",
      "Epoch:     60 loss= 5.193651 acc= 0.291353 cost_time= 0.294143s \n",
      "Epoch:     70 loss= 5.640871 acc= 0.383828 cost_time= 0.292812s \n",
      "Epoch:     80 loss= 5.977140 acc= 0.361634 cost_time= 0.293906s \n",
      "Epoch:     90 loss= 5.572269 acc= 0.395164 cost_time= 0.293389s \n",
      "Epoch:    100 loss= 5.325509 acc= 0.285767 cost_time= 0.295512s \n",
      "Epoch:    110 loss= 4.658325 acc= 0.313011 cost_time= 0.294985s \n",
      "Epoch:    120 loss= 5.253929 acc= 0.316948 cost_time= 0.294579s \n",
      "Epoch:    130 loss= 4.794215 acc= 0.301910 cost_time= 0.289138s \n",
      "Epoch:    140 loss= 4.310599 acc= 0.369818 cost_time= 0.291242s \n",
      "Epoch:    150 loss= 4.544971 acc= 0.366037 cost_time= 0.293249s \n",
      "Epoch:    160 loss= 4.455456 acc= 0.308096 cost_time= 0.291586s \n",
      "Epoch:    170 loss= 4.855807 acc= 0.418463 cost_time= 0.292361s \n",
      "Epoch:    180 loss= 4.853146 acc= 0.270379 cost_time= 0.295937s \n",
      "Epoch:    190 loss= 3.650914 acc= 0.340781 cost_time= 0.294082s \n",
      "Epoch:    200 loss= 4.704087 acc= 0.250072 cost_time= 0.294779s \n",
      "Epoch:    210 loss= 4.535350 acc= 0.370558 cost_time= 0.296300s \n",
      "Epoch:    220 loss= 4.479801 acc= 0.408592 cost_time= 0.294753s \n",
      "Epoch:    230 loss= 4.023021 acc= 0.369598 cost_time= 0.294281s \n",
      "Epoch:    240 loss= 3.861481 acc= 0.205133 cost_time= 0.294974s \n",
      "Epoch:    250 loss= 4.311852 acc= 0.259102 cost_time= 0.294294s \n",
      "Epoch:    260 loss= 4.099979 acc= 0.348974 cost_time= 0.295352s \n",
      "Epoch:    270 loss= 4.692856 acc= 0.313245 cost_time= 0.292631s \n",
      "Epoch:    280 loss= 4.485929 acc= 0.242209 cost_time= 0.297655s \n",
      "Epoch:    290 loss= 3.798464 acc= 0.346217 cost_time= 0.294426s \n",
      "Epoch:    300 loss= 3.676185 acc= 0.340522 cost_time= 0.291582s \n",
      "Epoch:    310 loss= 4.439688 acc= 0.276355 cost_time= 0.293610s \n",
      "Epoch:    320 loss= 3.740248 acc= 0.390193 cost_time= 0.295080s \n",
      "Epoch:    330 loss= 4.298654 acc= 0.323173 cost_time= 0.293561s \n",
      "Epoch:    340 loss= 3.803586 acc= 0.376385 cost_time= 0.291819s \n",
      "Epoch:    350 loss= 3.809803 acc= 0.345598 cost_time= 0.293979s \n",
      "Epoch:    360 loss= 3.161900 acc= 0.385669 cost_time= 0.293183s \n",
      "Epoch:    370 loss= 3.337218 acc= 0.348354 cost_time= 0.292547s \n",
      "Epoch:    380 loss= 3.297349 acc= 0.427505 cost_time= 0.293663s \n",
      "Epoch:    390 loss= 4.190812 acc= 0.343932 cost_time= 0.294974s \n",
      "Epoch:    400 loss= 4.372438 acc= 0.295765 cost_time= 0.294492s \n",
      "Epoch:    410 loss= 3.643196 acc= 0.410684 cost_time= 0.295319s \n",
      "Epoch:    420 loss= 4.419145 acc= 0.334789 cost_time= 0.295110s \n",
      "Epoch:    430 loss= 4.078823 acc= 0.340286 cost_time= 0.295347s \n",
      "Epoch:    440 loss= 4.265238 acc= 0.299457 cost_time= 0.299750s \n",
      "Epoch:    450 loss= 3.889809 acc= 0.322932 cost_time= 0.294534s \n",
      "Epoch:    460 loss= 4.109687 acc= 0.337184 cost_time= 0.295512s \n",
      "Epoch:    470 loss= 4.014287 acc= 0.291803 cost_time= 0.295637s \n",
      "Epoch:    480 loss= 4.299661 acc= 0.272342 cost_time= 0.297194s \n",
      "Epoch:    490 loss= 3.505093 acc= 0.281892 cost_time= 0.290597s \n",
      "Epoch:    500 loss= 4.066405 acc= 0.305583 cost_time= 0.293880s \n",
      "Epoch:    510 loss= 3.988142 acc= 0.286924 cost_time= 0.293948s \n",
      "Epoch:    520 loss= 3.653071 acc= 0.298399 cost_time= 0.293337s \n",
      "Epoch:    530 loss= 3.902265 acc= 0.275319 cost_time= 0.292864s \n",
      "Epoch:    540 loss= 3.722093 acc= 0.367087 cost_time= 0.294394s \n",
      "Epoch:    550 loss= 3.378078 acc= 0.419447 cost_time= 0.295267s \n",
      "Epoch:    560 loss= 4.192224 acc= 0.325397 cost_time= 0.293821s \n",
      "Epoch:    570 loss= 3.400759 acc= 0.344011 cost_time= 0.297928s \n",
      "Epoch:    580 loss= 3.698482 acc= 0.301810 cost_time= 0.293027s \n",
      "Epoch:    590 loss= 3.461033 acc= 0.381615 cost_time= 0.292951s \n",
      "Epoch:    600 loss= 3.920745 acc= 0.314762 cost_time= 0.295058s \n",
      "Epoch:    610 loss= 3.208677 acc= 0.424020 cost_time= 0.301020s \n",
      "Epoch:    620 loss= 3.745819 acc= 0.343879 cost_time= 0.292669s \n",
      "Epoch:    630 loss= 3.420382 acc= 0.368794 cost_time= 0.294844s \n",
      "Epoch:    640 loss= 3.458972 acc= 0.364046 cost_time= 0.294053s \n",
      "Epoch:    650 loss= 4.001223 acc= 0.278611 cost_time= 0.294515s \n",
      "Epoch:    660 loss= 3.615927 acc= 0.307105 cost_time= 0.293679s \n",
      "Epoch:    670 loss= 3.229712 acc= 0.379784 cost_time= 0.293225s \n",
      "Epoch:    680 loss= 3.300568 acc= 0.354331 cost_time= 0.293157s \n",
      "Epoch:    690 loss= 3.551990 acc= 0.330351 cost_time= 0.292628s \n",
      "Epoch:    700 loss= 3.696457 acc= 0.348213 cost_time= 0.293624s \n",
      "Epoch:    710 loss= 3.154945 acc= 0.326664 cost_time= 0.293042s \n",
      "Epoch:    720 loss= 3.942847 acc= 0.404302 cost_time= 0.292944s \n",
      "Epoch:    730 loss= 3.646646 acc= 0.323919 cost_time= 0.294631s \n",
      "Epoch:    740 loss= 3.157373 acc= 0.301683 cost_time= 0.294809s \n",
      "Epoch:    750 loss= 2.832066 acc= 0.402358 cost_time= 0.295633s \n",
      "Epoch:    760 loss= 3.173899 acc= 0.374845 cost_time= 0.295547s \n",
      "Epoch:    770 loss= 3.487119 acc= 0.294337 cost_time= 0.300673s \n",
      "Epoch:    780 loss= 3.164546 acc= 0.386138 cost_time= 0.299233s \n",
      "Epoch:    790 loss= 3.716188 acc= 0.283281 cost_time= 0.293955s \n",
      "Epoch:    800 loss= 3.767029 acc= 0.337827 cost_time= 0.294607s \n",
      "Epoch:    810 loss= 3.963081 acc= 0.328369 cost_time= 0.295279s \n",
      "Epoch:    820 loss= 3.917017 acc= 0.339665 cost_time= 0.293193s \n",
      "Epoch:    830 loss= 3.367203 acc= 0.367322 cost_time= 0.293308s \n",
      "Epoch:    840 loss= 3.439150 acc= 0.298959 cost_time= 0.294448s \n",
      "Epoch:    850 loss= 3.773600 acc= 0.329054 cost_time= 0.293575s \n",
      "Epoch:    860 loss= 3.078098 acc= 0.330377 cost_time= 0.294255s \n",
      "Epoch:    870 loss= 3.581967 acc= 0.272565 cost_time= 0.297371s \n",
      "Epoch:    880 loss= 3.153235 acc= 0.409360 cost_time= 0.297890s \n",
      "Epoch:    890 loss= 3.698325 acc= 0.267377 cost_time= 0.294508s \n",
      "Epoch:    900 loss= 3.631452 acc= 0.335050 cost_time= 0.296727s \n",
      "Epoch:    910 loss= 3.740685 acc= 0.412330 cost_time= 0.295672s \n",
      "Epoch:    920 loss= 3.562462 acc= 0.342451 cost_time= 0.295110s \n",
      "Epoch:    930 loss= 3.612559 acc= 0.360426 cost_time= 0.300226s \n",
      "Epoch:    940 loss= 3.475798 acc= 0.336880 cost_time= 0.293883s \n",
      "Epoch:    950 loss= 3.354286 acc= 0.348411 cost_time= 0.301323s \n",
      "Epoch:    960 loss= 3.674988 acc= 0.350129 cost_time= 0.308352s \n",
      "Epoch:    970 loss= 3.076695 acc= 0.363630 cost_time= 0.295387s \n",
      "Epoch:    980 loss= 3.095943 acc= 0.388477 cost_time= 0.293367s \n",
      "Epoch:    990 loss= 4.018931 acc= 0.363443 cost_time= 0.294595s \n",
      "Epoch:   1000 loss= 3.093148 acc= 0.354651 cost_time= 0.296158s \n",
      "Epoch:   1010 loss= 3.683732 acc= 0.392521 cost_time= 0.299122s \n",
      "Epoch:   1020 loss= 3.131672 acc= 0.362787 cost_time= 0.293770s \n",
      "Epoch:   1030 loss= 3.371938 acc= 0.298407 cost_time= 0.296322s \n",
      "Epoch:   1040 loss= 4.010490 acc= 0.336282 cost_time= 0.293896s \n",
      "Epoch:   1050 loss= 3.549537 acc= 0.356219 cost_time= 0.294353s \n",
      "Epoch:   1060 loss= 2.901911 acc= 0.361670 cost_time= 0.293229s \n",
      "Epoch:   1070 loss= 3.240413 acc= 0.333730 cost_time= 0.293753s \n",
      "Epoch:   1080 loss= 3.106111 acc= 0.422094 cost_time= 0.294814s \n",
      "Epoch:   1090 loss= 3.607924 acc= 0.407377 cost_time= 0.293327s \n",
      "Epoch:   1100 loss= 3.822955 acc= 0.355795 cost_time= 0.296771s \n",
      "Epoch:   1110 loss= 2.977558 acc= 0.360492 cost_time= 0.294424s \n",
      "Epoch:   1120 loss= 3.090622 acc= 0.326839 cost_time= 0.292920s \n",
      "Epoch:   1130 loss= 3.214740 acc= 0.379392 cost_time= 0.293314s \n",
      "Epoch:   1140 loss= 3.036398 acc= 0.462496 cost_time= 0.294935s \n",
      "Epoch:   1150 loss= 3.020483 acc= 0.279281 cost_time= 0.293525s \n",
      "Epoch:   1160 loss= 3.482872 acc= 0.375784 cost_time= 0.295424s \n",
      "Epoch:   1170 loss= 2.903221 acc= 0.400256 cost_time= 0.293877s \n",
      "Epoch:   1180 loss= 3.255557 acc= 0.283379 cost_time= 0.291856s \n",
      "Epoch:   1190 loss= 3.002358 acc= 0.339389 cost_time= 0.292668s \n",
      "Epoch:   1200 loss= 3.219234 acc= 0.402830 cost_time= 0.292823s \n",
      "Epoch:   1210 loss= 3.535525 acc= 0.364388 cost_time= 0.296407s \n",
      "Epoch:   1220 loss= 3.899525 acc= 0.399812 cost_time= 0.296413s \n",
      "Epoch:   1230 loss= 3.725782 acc= 0.407286 cost_time= 0.295345s \n",
      "Epoch:   1240 loss= 2.938745 acc= 0.339863 cost_time= 0.295520s \n",
      "Epoch:   1250 loss= 3.645817 acc= 0.400641 cost_time= 0.293604s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1260 loss= 3.433758 acc= 0.415382 cost_time= 0.292233s \n",
      "Epoch:   1270 loss= 3.555220 acc= 0.378549 cost_time= 0.294586s \n",
      "Epoch:   1280 loss= 3.501143 acc= 0.383386 cost_time= 0.295435s \n",
      "Epoch:   1290 loss= 3.211962 acc= 0.297363 cost_time= 0.292459s \n",
      "Epoch:   1300 loss= 2.845460 acc= 0.425253 cost_time= 0.293382s \n",
      "Epoch:   1310 loss= 2.946643 acc= 0.306164 cost_time= 0.294428s \n",
      "Epoch:   1320 loss= 3.261962 acc= 0.327055 cost_time= 0.290941s \n",
      "Epoch:   1330 loss= 3.464645 acc= 0.414156 cost_time= 0.295951s \n",
      "Epoch:   1340 loss= 3.635767 acc= 0.356329 cost_time= 0.290947s \n",
      "Epoch:   1350 loss= 3.539893 acc= 0.300262 cost_time= 0.294216s \n",
      "Epoch:   1360 loss= 3.671062 acc= 0.314592 cost_time= 0.293254s \n",
      "Epoch:   1370 loss= 3.575707 acc= 0.337576 cost_time= 0.291609s \n",
      "Epoch:   1380 loss= 2.410733 acc= 0.377910 cost_time= 0.293071s \n",
      "Epoch:   1390 loss= 3.031698 acc= 0.416439 cost_time= 0.292940s \n",
      "Epoch:   1400 loss= 3.052863 acc= 0.415274 cost_time= 0.295210s \n",
      "Epoch:   1410 loss= 2.772604 acc= 0.352439 cost_time= 0.294079s \n",
      "Epoch:   1420 loss= 3.177964 acc= 0.359542 cost_time= 0.293503s \n",
      "Epoch:   1430 loss= 3.378012 acc= 0.388666 cost_time= 0.293346s \n",
      "Epoch:   1440 loss= 3.379815 acc= 0.345501 cost_time= 0.296390s \n",
      "Epoch:   1450 loss= 2.767623 acc= 0.259045 cost_time= 0.292586s \n",
      "Epoch:   1460 loss= 3.059378 acc= 0.308373 cost_time= 0.293850s \n",
      "Epoch:   1470 loss= 3.287425 acc= 0.323399 cost_time= 0.293868s \n",
      "Epoch:   1480 loss= 3.462649 acc= 0.402017 cost_time= 0.297618s \n",
      "Epoch:   1490 loss= 3.073299 acc= 0.404628 cost_time= 0.294529s \n",
      "Epoch:   1500 loss= 3.452079 acc= 0.243453 cost_time= 0.295491s \n",
      "Epoch:   1510 loss= 3.070517 acc= 0.382712 cost_time= 0.296603s \n",
      "Epoch:   1520 loss= 2.989580 acc= 0.361481 cost_time= 0.293500s \n",
      "Epoch:   1530 loss= 3.474918 acc= 0.327774 cost_time= 0.294296s \n",
      "Epoch:   1540 loss= 3.191482 acc= 0.390336 cost_time= 0.294445s \n",
      "Epoch:   1550 loss= 3.386378 acc= 0.445817 cost_time= 0.293453s \n",
      "Epoch:   1560 loss= 3.328700 acc= 0.352541 cost_time= 0.295763s \n",
      "Epoch:   1570 loss= 2.787674 acc= 0.423819 cost_time= 0.294545s \n",
      "Epoch:   1580 loss= 3.814650 acc= 0.351398 cost_time= 0.293322s \n",
      "Epoch:   1590 loss= 2.927176 acc= 0.426432 cost_time= 0.294524s \n",
      "Epoch:   1600 loss= 3.154033 acc= 0.396978 cost_time= 0.294936s \n",
      "Epoch:   1610 loss= 2.986026 acc= 0.437466 cost_time= 0.295569s \n",
      "Epoch:   1620 loss= 2.893640 acc= 0.385015 cost_time= 0.294217s \n",
      "Epoch:   1630 loss= 3.220012 acc= 0.290300 cost_time= 0.292925s \n",
      "Epoch:   1640 loss= 3.525943 acc= 0.324741 cost_time= 0.296311s \n",
      "Epoch:   1650 loss= 3.370809 acc= 0.378818 cost_time= 0.292829s \n",
      "Epoch:   1660 loss= 4.067826 acc= 0.327635 cost_time= 0.292611s \n",
      "Epoch:   1670 loss= 3.833584 acc= 0.395376 cost_time= 0.292967s \n",
      "Epoch:   1680 loss= 3.458524 acc= 0.312645 cost_time= 0.293822s \n",
      "Epoch:   1690 loss= 3.509212 acc= 0.428972 cost_time= 0.292906s \n",
      "Epoch:   1700 loss= 3.466930 acc= 0.293851 cost_time= 0.292251s \n",
      "Epoch:   1710 loss= 3.501257 acc= 0.395555 cost_time= 0.293072s \n",
      "Epoch:   1720 loss= 2.615834 acc= 0.454139 cost_time= 0.291828s \n",
      "Epoch:   1730 loss= 3.091278 acc= 0.379614 cost_time= 0.293799s \n",
      "Epoch:   1740 loss= 3.011164 acc= 0.417968 cost_time= 0.293238s \n",
      "Epoch:   1750 loss= 3.489500 acc= 0.408884 cost_time= 0.293873s \n",
      "Epoch:   1760 loss= 3.136779 acc= 0.381893 cost_time= 0.297605s \n",
      "Epoch:   1770 loss= 3.676268 acc= 0.378314 cost_time= 0.292784s \n",
      "Epoch:   1780 loss= 2.706877 acc= 0.384117 cost_time= 0.293229s \n",
      "Epoch:   1790 loss= 3.678062 acc= 0.397276 cost_time= 0.292421s \n",
      "Epoch:   1800 loss= 3.245405 acc= 0.455706 cost_time= 0.293015s \n",
      "Epoch:   1810 loss= 3.137483 acc= 0.469232 cost_time= 0.292221s \n",
      "Epoch:   1820 loss= 2.779823 acc= 0.458171 cost_time= 0.293868s \n",
      "Epoch:   1830 loss= 2.930155 acc= 0.402247 cost_time= 0.293545s \n",
      "Epoch:   1840 loss= 3.144481 acc= 0.432554 cost_time= 0.295319s \n",
      "Epoch:   1850 loss= 3.003239 acc= 0.375520 cost_time= 0.294231s \n",
      "Epoch:   1860 loss= 3.300561 acc= 0.400343 cost_time= 0.292045s \n",
      "Epoch:   1870 loss= 2.908184 acc= 0.446026 cost_time= 0.293629s \n",
      "Epoch:   1880 loss= 2.722544 acc= 0.400835 cost_time= 0.293529s \n",
      "Epoch:   1890 loss= 3.209042 acc= 0.370096 cost_time= 0.295653s \n",
      "Epoch:   1900 loss= 3.945851 acc= 0.439953 cost_time= 0.294084s \n",
      "Epoch:   1910 loss= 3.205215 acc= 0.362514 cost_time= 0.293277s \n",
      "Epoch:   1920 loss= 4.344608 acc= 0.332551 cost_time= 0.293146s \n",
      "Epoch:   1930 loss= 3.446207 acc= 0.430581 cost_time= 0.296040s \n",
      "Epoch:   1940 loss= 3.159597 acc= 0.396311 cost_time= 0.295209s \n",
      "Epoch:   1950 loss= 3.316653 acc= 0.266133 cost_time= 0.292811s \n",
      "Epoch:   1960 loss= 3.111303 acc= 0.393403 cost_time= 0.293609s \n",
      "Epoch:   1970 loss= 2.924304 acc= 0.390806 cost_time= 0.294071s \n",
      "Epoch:   1980 loss= 3.137233 acc= 0.244155 cost_time= 0.293272s \n",
      "Epoch:   1990 loss= 3.171490 acc= 0.476197 cost_time= 0.292534s \n",
      "Epoch:   2000 loss= 3.076156 acc= 0.429632 cost_time= 0.293821s \n",
      "Epoch:   2010 loss= 3.063948 acc= 0.352112 cost_time= 0.294561s \n",
      "Epoch:   2020 loss= 3.994853 acc= 0.303179 cost_time= 0.291587s \n",
      "Epoch:   2030 loss= 2.791160 acc= 0.348331 cost_time= 0.292929s \n",
      "Epoch:   2040 loss= 3.337367 acc= 0.435031 cost_time= 0.293018s \n",
      "Epoch:   2050 loss= 3.202581 acc= 0.407644 cost_time= 0.293152s \n",
      "Epoch:   2060 loss= 3.296981 acc= 0.424505 cost_time= 0.292406s \n",
      "Epoch:   2070 loss= 3.177741 acc= 0.355509 cost_time= 0.290918s \n",
      "Epoch:   2080 loss= 3.346733 acc= 0.353795 cost_time= 0.294979s \n",
      "Epoch:   2090 loss= 3.711257 acc= 0.320786 cost_time= 0.295284s \n",
      "Epoch:   2100 loss= 3.516361 acc= 0.431082 cost_time= 0.295968s \n",
      "Epoch:   2110 loss= 2.480465 acc= 0.405940 cost_time= 0.293319s \n",
      "Epoch:   2120 loss= 3.452319 acc= 0.302676 cost_time= 0.294464s \n",
      "Epoch:   2130 loss= 3.684834 acc= 0.374207 cost_time= 0.292143s \n",
      "Epoch:   2140 loss= 3.218696 acc= 0.392461 cost_time= 0.292757s \n",
      "Epoch:   2150 loss= 3.061569 acc= 0.353580 cost_time= 0.292392s \n",
      "Epoch:   2160 loss= 2.667845 acc= 0.348616 cost_time= 0.294848s \n",
      "Epoch:   2170 loss= 2.917919 acc= 0.445178 cost_time= 0.292800s \n",
      "Epoch:   2180 loss= 3.067830 acc= 0.313608 cost_time= 0.293729s \n",
      "Epoch:   2190 loss= 2.437752 acc= 0.455800 cost_time= 0.294808s \n",
      "Epoch:   2200 loss= 3.357696 acc= 0.382323 cost_time= 0.293829s \n",
      "Epoch:   2210 loss= 3.603508 acc= 0.442689 cost_time= 0.296283s \n",
      "Epoch:   2220 loss= 3.220371 acc= 0.309467 cost_time= 0.290988s \n",
      "Epoch:   2230 loss= 2.735219 acc= 0.458644 cost_time= 0.292224s \n",
      "Epoch:   2240 loss= 2.508704 acc= 0.378806 cost_time= 0.297609s \n",
      "Epoch:   2250 loss= 3.355951 acc= 0.359374 cost_time= 0.291983s \n",
      "Epoch:   2260 loss= 3.045624 acc= 0.418588 cost_time= 0.294320s \n",
      "Epoch:   2270 loss= 3.319287 acc= 0.361057 cost_time= 0.294024s \n",
      "Epoch:   2280 loss= 4.346961 acc= 0.341837 cost_time= 0.294928s \n",
      "Epoch:   2290 loss= 3.520056 acc= 0.334116 cost_time= 0.294426s \n",
      "Epoch:   2300 loss= 2.776147 acc= 0.482301 cost_time= 0.291407s \n",
      "Epoch:   2310 loss= 3.353875 acc= 0.333190 cost_time= 0.294016s \n",
      "Epoch:   2320 loss= 3.251897 acc= 0.352021 cost_time= 0.292306s \n",
      "Epoch:   2330 loss= 2.975807 acc= 0.417675 cost_time= 0.294940s \n",
      "Epoch:   2340 loss= 2.942782 acc= 0.343134 cost_time= 0.294140s \n",
      "Epoch:   2350 loss= 3.044076 acc= 0.408618 cost_time= 0.294391s \n",
      "Epoch:   2360 loss= 3.296851 acc= 0.423839 cost_time= 0.295295s \n",
      "Epoch:   2370 loss= 2.759861 acc= 0.423567 cost_time= 0.292817s \n",
      "Epoch:   2380 loss= 3.426438 acc= 0.401727 cost_time= 0.294602s \n",
      "Epoch:   2390 loss= 3.117434 acc= 0.400063 cost_time= 0.293035s \n",
      "Epoch:   2400 loss= 3.635073 acc= 0.377273 cost_time= 0.294782s \n",
      "Epoch:   2410 loss= 3.377298 acc= 0.411413 cost_time= 0.296913s \n",
      "Epoch:   2420 loss= 3.641168 acc= 0.409160 cost_time= 0.292610s \n",
      "Epoch:   2430 loss= 3.090382 acc= 0.409268 cost_time= 0.292618s \n",
      "Epoch:   2440 loss= 3.859358 acc= 0.408887 cost_time= 0.295516s \n",
      "Epoch:   2450 loss= 2.033242 acc= 0.398890 cost_time= 0.293256s \n",
      "Epoch:   2460 loss= 3.217878 acc= 0.443334 cost_time= 0.292774s \n",
      "Epoch:   2470 loss= 3.591155 acc= 0.345979 cost_time= 0.292901s \n",
      "Epoch:   2480 loss= 3.010314 acc= 0.340745 cost_time= 0.292949s \n",
      "Epoch:   2490 loss= 3.112215 acc= 0.388750 cost_time= 0.294210s \n",
      "Epoch:   2500 loss= 3.247577 acc= 0.389224 cost_time= 0.293961s \n",
      "Epoch:   2510 loss= 3.300941 acc= 0.369400 cost_time= 0.296462s \n",
      "Epoch:   2520 loss= 3.103095 acc= 0.407975 cost_time= 0.292795s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2530 loss= 3.593939 acc= 0.373911 cost_time= 0.293595s \n",
      "Epoch:   2540 loss= 3.128986 acc= 0.424756 cost_time= 0.293202s \n",
      "Epoch:   2550 loss= 3.440456 acc= 0.375093 cost_time= 0.294208s \n",
      "Epoch:   2560 loss= 2.849823 acc= 0.434927 cost_time= 0.291996s \n",
      "Epoch:   2570 loss= 2.722015 acc= 0.495094 cost_time= 0.292901s \n",
      "Epoch:   2580 loss= 3.480506 acc= 0.374355 cost_time= 0.295512s \n",
      "Epoch:   2590 loss= 3.475811 acc= 0.428158 cost_time= 0.293237s \n",
      "Epoch:   2600 loss= 3.118308 acc= 0.394529 cost_time= 0.292515s \n",
      "Epoch:   2610 loss= 2.819438 acc= 0.422390 cost_time= 0.292113s \n",
      "Epoch:   2620 loss= 3.529222 acc= 0.282087 cost_time= 0.294335s \n",
      "Epoch:   2630 loss= 2.390231 acc= 0.400710 cost_time= 0.293323s \n",
      "Epoch:   2640 loss= 3.088322 acc= 0.447815 cost_time= 0.295890s \n",
      "Epoch:   2650 loss= 3.322628 acc= 0.419487 cost_time= 0.294492s \n",
      "Epoch:   2660 loss= 3.019141 acc= 0.342830 cost_time= 0.292079s \n",
      "Epoch:   2670 loss= 3.253369 acc= 0.424477 cost_time= 0.292453s \n",
      "Epoch:   2680 loss= 3.081600 acc= 0.440908 cost_time= 0.294465s \n",
      "Epoch:   2690 loss= 3.527773 acc= 0.361277 cost_time= 0.291599s \n",
      "Epoch:   2700 loss= 2.950480 acc= 0.396728 cost_time= 0.293221s \n",
      "Epoch:   2710 loss= 3.298271 acc= 0.312097 cost_time= 0.295187s \n",
      "Epoch:   2720 loss= 3.114021 acc= 0.470817 cost_time= 0.293739s \n",
      "Epoch:   2730 loss= 3.604498 acc= 0.352576 cost_time= 0.294911s \n",
      "Epoch:   2740 loss= 2.922041 acc= 0.400790 cost_time= 0.291250s \n",
      "Epoch:   2750 loss= 3.083531 acc= 0.435775 cost_time= 0.293249s \n",
      "Epoch:   2760 loss= 2.912893 acc= 0.335442 cost_time= 0.295058s \n",
      "Epoch:   2770 loss= 3.506159 acc= 0.427178 cost_time= 0.294235s \n",
      "Epoch:   2780 loss= 3.078915 acc= 0.391966 cost_time= 0.293360s \n",
      "Epoch:   2790 loss= 3.409664 acc= 0.443920 cost_time= 0.293773s \n",
      "Epoch:   2800 loss= 3.334191 acc= 0.438902 cost_time= 0.292858s \n",
      "Epoch:   2810 loss= 2.748545 acc= 0.374924 cost_time= 0.294340s \n",
      "Epoch:   2820 loss= 3.191014 acc= 0.340124 cost_time= 0.292073s \n",
      "Epoch:   2830 loss= 3.235619 acc= 0.353420 cost_time= 0.294909s \n",
      "Epoch:   2840 loss= 2.645314 acc= 0.375526 cost_time= 0.294642s \n",
      "Epoch:   2850 loss= 2.868850 acc= 0.352688 cost_time= 0.290701s \n",
      "Epoch:   2860 loss= 3.060096 acc= 0.336191 cost_time= 0.294117s \n",
      "Epoch:   2870 loss= 3.034981 acc= 0.361352 cost_time= 0.294409s \n",
      "Epoch:   2880 loss= 2.794931 acc= 0.421619 cost_time= 0.296417s \n",
      "Epoch:   2890 loss= 3.361852 acc= 0.390311 cost_time= 0.292192s \n",
      "Epoch:   2900 loss= 2.821517 acc= 0.404969 cost_time= 0.292461s \n",
      "Epoch:   2910 loss= 2.991300 acc= 0.399635 cost_time= 0.292719s \n",
      "Epoch:   2920 loss= 2.938287 acc= 0.404937 cost_time= 0.294237s \n",
      "Epoch:   2930 loss= 3.646345 acc= 0.246475 cost_time= 0.294443s \n",
      "Epoch:   2940 loss= 3.020611 acc= 0.450732 cost_time= 0.292246s \n",
      "Epoch:   2950 loss= 2.488462 acc= 0.440912 cost_time= 0.294493s \n",
      "Epoch:   2960 loss= 2.671898 acc= 0.358762 cost_time= 0.292505s \n",
      "Epoch:   2970 loss= 3.883043 acc= 0.275666 cost_time= 0.293082s \n",
      "Epoch:   2980 loss= 3.125532 acc= 0.441199 cost_time= 0.293885s \n",
      "Epoch:   2990 loss= 3.132226 acc= 0.350670 cost_time= 0.292679s \n",
      "Epoch:   3000 loss= 2.973240 acc= 0.394992 cost_time= 0.293735s \n",
      "Epoch:   3010 loss= 3.060264 acc= 0.381473 cost_time= 0.293769s \n",
      "Epoch:   3020 loss= 2.871251 acc= 0.386445 cost_time= 0.292121s \n",
      "Epoch:   3030 loss= 2.561154 acc= 0.369865 cost_time= 0.292357s \n",
      "Epoch:   3040 loss= 2.778167 acc= 0.412892 cost_time= 0.292359s \n",
      "Epoch:   3050 loss= 2.805483 acc= 0.481409 cost_time= 0.293616s \n",
      "Epoch:   3060 loss= 2.749276 acc= 0.494964 cost_time= 0.291137s \n",
      "Epoch:   3070 loss= 3.537524 acc= 0.364780 cost_time= 0.292665s \n",
      "Epoch:   3080 loss= 2.813068 acc= 0.322540 cost_time= 0.292329s \n",
      "Epoch:   3090 loss= 3.684668 acc= 0.423659 cost_time= 0.291791s \n",
      "Epoch:   3100 loss= 3.077323 acc= 0.363357 cost_time= 0.294945s \n",
      "Epoch:   3110 loss= 3.052108 acc= 0.415418 cost_time= 0.291690s \n",
      "Epoch:   3120 loss= 2.639455 acc= 0.381765 cost_time= 0.295239s \n",
      "Epoch:   3130 loss= 3.038307 acc= 0.365136 cost_time= 0.294014s \n",
      "Epoch:   3140 loss= 3.295979 acc= 0.427753 cost_time= 0.295326s \n",
      "Epoch:   3150 loss= 2.524657 acc= 0.467020 cost_time= 0.295834s \n",
      "Epoch:   3160 loss= 3.046754 acc= 0.419851 cost_time= 0.293093s \n",
      "Epoch:   3170 loss= 3.300919 acc= 0.404787 cost_time= 0.292753s \n",
      "Epoch:   3180 loss= 2.728874 acc= 0.433296 cost_time= 0.290624s \n",
      "Epoch:   3190 loss= 2.870538 acc= 0.460747 cost_time= 0.293669s \n",
      "Epoch:   3200 loss= 2.605624 acc= 0.395362 cost_time= 0.293120s \n",
      "Epoch:   3210 loss= 3.391182 acc= 0.400257 cost_time= 0.296606s \n",
      "Epoch:   3220 loss= 3.150154 acc= 0.367125 cost_time= 0.294883s \n",
      "Epoch:   3230 loss= 3.000314 acc= 0.308154 cost_time= 0.293237s \n",
      "Epoch:   3240 loss= 2.926361 acc= 0.335739 cost_time= 0.292428s \n",
      "Epoch:   3250 loss= 2.741999 acc= 0.411662 cost_time= 0.293536s \n",
      "Epoch:   3260 loss= 3.676979 acc= 0.326481 cost_time= 0.294010s \n",
      "Epoch:   3270 loss= 2.772545 acc= 0.408098 cost_time= 0.293838s \n",
      "Epoch:   3280 loss= 3.112571 acc= 0.421444 cost_time= 0.293173s \n",
      "Epoch:   3290 loss= 2.952214 acc= 0.445008 cost_time= 0.293179s \n",
      "Epoch:   3300 loss= 3.010113 acc= 0.402259 cost_time= 0.293451s \n",
      "Epoch:   3310 loss= 3.023409 acc= 0.447823 cost_time= 0.291100s \n",
      "Epoch:   3320 loss= 4.100672 acc= 0.369366 cost_time= 0.291345s \n",
      "Epoch:   3330 loss= 2.541166 acc= 0.408654 cost_time= 0.296822s \n",
      "Epoch:   3340 loss= 3.175236 acc= 0.333949 cost_time= 0.297831s \n",
      "Epoch:   3350 loss= 3.644057 acc= 0.386288 cost_time= 0.299690s \n",
      "Epoch:   3360 loss= 2.854733 acc= 0.410860 cost_time= 0.293435s \n",
      "Epoch:   3370 loss= 2.215237 acc= 0.396487 cost_time= 0.292533s \n",
      "Epoch:   3380 loss= 2.665795 acc= 0.379010 cost_time= 0.293781s \n",
      "Epoch:   3390 loss= 3.656057 acc= 0.384659 cost_time= 0.295917s \n",
      "Epoch:   3400 loss= 2.444881 acc= 0.501736 cost_time= 0.291237s \n",
      "Epoch:   3410 loss= 2.705895 acc= 0.519809 cost_time= 0.292692s \n",
      "Epoch:   3420 loss= 3.045475 acc= 0.400790 cost_time= 0.291561s \n",
      "Epoch:   3430 loss= 2.770371 acc= 0.362355 cost_time= 0.295464s \n",
      "Epoch:   3440 loss= 3.310978 acc= 0.415300 cost_time= 0.292452s \n",
      "Epoch:   3450 loss= 3.297340 acc= 0.415745 cost_time= 0.293302s \n",
      "Epoch:   3460 loss= 2.854006 acc= 0.458887 cost_time= 0.294425s \n",
      "Epoch:   3470 loss= 3.369331 acc= 0.412347 cost_time= 0.293827s \n",
      "Epoch:   3480 loss= 2.627559 acc= 0.395617 cost_time= 0.293985s \n",
      "Epoch:   3490 loss= 2.703498 acc= 0.403393 cost_time= 0.293255s \n",
      "Epoch:   3500 loss= 2.427397 acc= 0.385242 cost_time= 0.292868s \n",
      "Epoch:   3510 loss= 3.151901 acc= 0.424943 cost_time= 0.292937s \n",
      "Epoch:   3520 loss= 2.395871 acc= 0.425400 cost_time= 0.292412s \n",
      "Epoch:   3530 loss= 2.720088 acc= 0.460137 cost_time= 0.295534s \n",
      "Epoch:   3540 loss= 2.749411 acc= 0.420981 cost_time= 0.293768s \n",
      "Epoch:   3550 loss= 2.769828 acc= 0.323439 cost_time= 0.291781s \n",
      "Epoch:   3560 loss= 2.790700 acc= 0.350493 cost_time= 0.294952s \n",
      "Epoch:   3570 loss= 2.878561 acc= 0.410640 cost_time= 0.293221s \n",
      "Epoch:   3580 loss= 3.075770 acc= 0.304924 cost_time= 0.293411s \n",
      "Epoch:   3590 loss= 3.415487 acc= 0.413832 cost_time= 0.291295s \n",
      "Epoch:   3600 loss= 3.314569 acc= 0.347770 cost_time= 0.292939s \n",
      "Epoch:   3610 loss= 3.226184 acc= 0.281043 cost_time= 0.298134s \n",
      "Epoch:   3620 loss= 2.922052 acc= 0.425032 cost_time= 0.296889s \n",
      "Epoch:   3630 loss= 3.111992 acc= 0.344738 cost_time= 0.295720s \n",
      "Epoch:   3640 loss= 2.655241 acc= 0.449296 cost_time= 0.299311s \n",
      "Epoch:   3650 loss= 3.135723 acc= 0.389815 cost_time= 0.291868s \n",
      "Epoch:   3660 loss= 2.995729 acc= 0.390237 cost_time= 0.293131s \n",
      "Epoch:   3670 loss= 3.290792 acc= 0.395615 cost_time= 0.292269s \n",
      "Epoch:   3680 loss= 2.918597 acc= 0.458221 cost_time= 0.292598s \n",
      "Epoch:   3690 loss= 3.048199 acc= 0.419488 cost_time= 0.291577s \n",
      "Epoch:   3700 loss= 3.576915 acc= 0.422425 cost_time= 0.294341s \n",
      "Epoch:   3710 loss= 3.067102 acc= 0.399614 cost_time= 0.294728s \n",
      "Epoch:   3720 loss= 2.690901 acc= 0.386929 cost_time= 0.296870s \n",
      "Epoch:   3730 loss= 2.575891 acc= 0.406098 cost_time= 0.295843s \n",
      "Epoch:   3740 loss= 3.349889 acc= 0.454407 cost_time= 0.294972s \n",
      "Epoch:   3750 loss= 2.296662 acc= 0.345830 cost_time= 0.294498s \n",
      "Epoch:   3760 loss= 2.626226 acc= 0.338669 cost_time= 0.294232s \n",
      "Epoch:   3770 loss= 2.754161 acc= 0.375167 cost_time= 0.293666s \n",
      "Epoch:   3780 loss= 3.395370 acc= 0.390650 cost_time= 0.293056s \n",
      "Epoch:   3790 loss= 3.490871 acc= 0.390577 cost_time= 0.294829s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3800 loss= 2.980522 acc= 0.471971 cost_time= 0.293500s \n",
      "Epoch:   3810 loss= 2.472044 acc= 0.502360 cost_time= 0.292713s \n",
      "Epoch:   3820 loss= 2.748534 acc= 0.474322 cost_time= 0.293554s \n",
      "Epoch:   3830 loss= 2.980238 acc= 0.420239 cost_time= 0.292938s \n",
      "Epoch:   3840 loss= 3.028764 acc= 0.406952 cost_time= 0.292156s \n",
      "Epoch:   3850 loss= 2.836591 acc= 0.494434 cost_time= 0.294765s \n",
      "Epoch:   3860 loss= 3.065644 acc= 0.410550 cost_time= 0.291967s \n",
      "Epoch:   3870 loss= 2.985263 acc= 0.462161 cost_time= 0.292480s \n",
      "Epoch:   3880 loss= 3.233496 acc= 0.458076 cost_time= 0.293432s \n",
      "Epoch:   3890 loss= 2.724953 acc= 0.438379 cost_time= 0.292907s \n",
      "Epoch:   3900 loss= 2.940472 acc= 0.411136 cost_time= 0.293187s \n",
      "Epoch:   3910 loss= 3.546916 acc= 0.347548 cost_time= 0.294499s \n",
      "Epoch:   3920 loss= 2.811404 acc= 0.408273 cost_time= 0.295620s \n",
      "Epoch:   3930 loss= 2.529378 acc= 0.468908 cost_time= 0.294667s \n",
      "Epoch:   3940 loss= 2.879060 acc= 0.464592 cost_time= 0.293200s \n",
      "Epoch:   3950 loss= 2.919613 acc= 0.442598 cost_time= 0.296095s \n",
      "Epoch:   3960 loss= 3.007045 acc= 0.376433 cost_time= 0.294015s \n",
      "Epoch:   3970 loss= 3.177603 acc= 0.407723 cost_time= 0.295827s \n",
      "Epoch:   3980 loss= 3.134102 acc= 0.388658 cost_time= 0.295385s \n",
      "Epoch:   3990 loss= 2.489903 acc= 0.395708 cost_time= 0.295227s \n",
      "Epoch:   4000 loss= 3.050018 acc= 0.492385 cost_time= 0.294386s \n",
      "Epoch:   4010 loss= 3.120572 acc= 0.424766 cost_time= 0.293140s \n",
      "Epoch:   4020 loss= 2.651946 acc= 0.393130 cost_time= 0.293684s \n",
      "Epoch:   4030 loss= 3.411349 acc= 0.351917 cost_time= 0.292357s \n",
      "Epoch:   4040 loss= 3.370869 acc= 0.410354 cost_time= 0.293883s \n",
      "Epoch:   4050 loss= 3.230193 acc= 0.328971 cost_time= 0.295968s \n",
      "Epoch:   4060 loss= 3.010056 acc= 0.423443 cost_time= 0.294379s \n",
      "Epoch:   4070 loss= 3.383193 acc= 0.325068 cost_time= 0.293982s \n",
      "Epoch:   4080 loss= 2.550009 acc= 0.388223 cost_time= 0.290449s \n",
      "Epoch:   4090 loss= 2.797410 acc= 0.362226 cost_time= 0.291778s \n",
      "Epoch:   4100 loss= 2.748163 acc= 0.431836 cost_time= 0.292401s \n",
      "Epoch:   4110 loss= 2.807872 acc= 0.457050 cost_time= 0.294997s \n",
      "Epoch:   4120 loss= 3.249363 acc= 0.446350 cost_time= 0.295340s \n",
      "Epoch:   4130 loss= 3.179129 acc= 0.431298 cost_time= 0.294143s \n",
      "Epoch:   4140 loss= 3.592215 acc= 0.387321 cost_time= 0.294111s \n",
      "Epoch:   4150 loss= 2.865879 acc= 0.416224 cost_time= 0.292934s \n",
      "Epoch:   4160 loss= 3.122486 acc= 0.488957 cost_time= 0.295777s \n",
      "Epoch:   4170 loss= 2.921346 acc= 0.495255 cost_time= 0.293660s \n",
      "Epoch:   4180 loss= 2.636143 acc= 0.425985 cost_time= 0.292649s \n",
      "Epoch:   4190 loss= 3.431027 acc= 0.411627 cost_time= 0.295405s \n",
      "Epoch:   4200 loss= 2.487327 acc= 0.441464 cost_time= 0.291023s \n",
      "Epoch:   4210 loss= 2.920375 acc= 0.530811 cost_time= 0.292629s \n",
      "Epoch:   4220 loss= 2.952140 acc= 0.370149 cost_time= 0.293875s \n",
      "Epoch:   4230 loss= 3.093006 acc= 0.453102 cost_time= 0.293004s \n",
      "Epoch:   4240 loss= 3.079324 acc= 0.358910 cost_time= 0.295239s \n",
      "Epoch:   4250 loss= 3.157313 acc= 0.386817 cost_time= 0.293227s \n",
      "Epoch:   4260 loss= 3.003423 acc= 0.409333 cost_time= 0.294634s \n",
      "Epoch:   4270 loss= 3.522213 acc= 0.398861 cost_time= 0.294546s \n",
      "Epoch:   4280 loss= 2.936682 acc= 0.491051 cost_time= 0.297163s \n",
      "Epoch:   4290 loss= 2.531479 acc= 0.271826 cost_time= 0.292645s \n",
      "Epoch:   4300 loss= 2.794487 acc= 0.407417 cost_time= 0.290849s \n",
      "Epoch:   4310 loss= 2.612867 acc= 0.417154 cost_time= 0.296820s \n",
      "Epoch:   4320 loss= 2.674500 acc= 0.397430 cost_time= 0.296377s \n",
      "Epoch:   4330 loss= 2.811714 acc= 0.493272 cost_time= 0.292315s \n",
      "Epoch:   4340 loss= 2.700763 acc= 0.432777 cost_time= 0.293288s \n",
      "Epoch:   4350 loss= 3.409122 acc= 0.390942 cost_time= 0.292595s \n",
      "Epoch:   4360 loss= 3.058866 acc= 0.372690 cost_time= 0.291794s \n",
      "Epoch:   4370 loss= 3.707501 acc= 0.378918 cost_time= 0.291553s \n",
      "Epoch:   4380 loss= 2.700134 acc= 0.405042 cost_time= 0.294982s \n",
      "Epoch:   4390 loss= 3.342030 acc= 0.367652 cost_time= 0.293142s \n",
      "Epoch:   4400 loss= 2.571540 acc= 0.387533 cost_time= 0.294815s \n",
      "Epoch:   4410 loss= 2.505845 acc= 0.461603 cost_time= 0.293511s \n",
      "Epoch:   4420 loss= 2.664788 acc= 0.442799 cost_time= 0.293988s \n",
      "Epoch:   4430 loss= 2.892214 acc= 0.430640 cost_time= 0.294106s \n",
      "Epoch:   4440 loss= 3.712646 acc= 0.394944 cost_time= 0.292924s \n",
      "Epoch:   4450 loss= 2.970237 acc= 0.378199 cost_time= 0.292567s \n",
      "Epoch:   4460 loss= 2.870369 acc= 0.427460 cost_time= 0.294836s \n",
      "Epoch:   4470 loss= 3.102358 acc= 0.418466 cost_time= 0.293449s \n",
      "Epoch:   4480 loss= 2.794956 acc= 0.551105 cost_time= 0.295245s \n",
      "Epoch:   4490 loss= 3.097966 acc= 0.438664 cost_time= 0.290992s \n",
      "Epoch:   4500 loss= 2.702319 acc= 0.378734 cost_time= 0.291598s \n",
      "Epoch:   4510 loss= 3.224058 acc= 0.360270 cost_time= 0.295284s \n",
      "Epoch:   4520 loss= 2.886333 acc= 0.423101 cost_time= 0.292439s \n",
      "Epoch:   4530 loss= 2.605844 acc= 0.473697 cost_time= 0.294310s \n",
      "Epoch:   4540 loss= 2.516871 acc= 0.404255 cost_time= 0.294364s \n",
      "Epoch:   4550 loss= 2.887652 acc= 0.502971 cost_time= 0.294371s \n",
      "Epoch:   4560 loss= 3.282134 acc= 0.391492 cost_time= 0.296141s \n",
      "Epoch:   4570 loss= 2.762311 acc= 0.507563 cost_time= 0.292026s \n",
      "Epoch:   4580 loss= 3.105108 acc= 0.379775 cost_time= 0.294468s \n",
      "Epoch:   4590 loss= 3.089974 acc= 0.456655 cost_time= 0.293632s \n",
      "Epoch:   4600 loss= 3.217589 acc= 0.403127 cost_time= 0.293867s \n",
      "Epoch:   4610 loss= 2.553068 acc= 0.489201 cost_time= 0.298255s \n",
      "Epoch:   4620 loss= 2.313659 acc= 0.392976 cost_time= 0.292474s \n",
      "Epoch:   4630 loss= 2.888017 acc= 0.399705 cost_time= 0.292701s \n",
      "Epoch:   4640 loss= 2.927973 acc= 0.539832 cost_time= 0.293462s \n",
      "Epoch:   4650 loss= 2.997787 acc= 0.422561 cost_time= 0.292164s \n",
      "Epoch:   4660 loss= 2.958846 acc= 0.439132 cost_time= 0.292712s \n",
      "Epoch:   4670 loss= 2.999191 acc= 0.496609 cost_time= 0.295431s \n",
      "Epoch:   4680 loss= 2.698018 acc= 0.384833 cost_time= 0.293497s \n",
      "Epoch:   4690 loss= 3.336907 acc= 0.394067 cost_time= 0.293867s \n",
      "Epoch:   4700 loss= 3.111578 acc= 0.370275 cost_time= 0.293969s \n",
      "Epoch:   4710 loss= 2.384686 acc= 0.499234 cost_time= 0.295622s \n",
      "Epoch:   4720 loss= 2.726943 acc= 0.425144 cost_time= 0.294170s \n",
      "Epoch:   4730 loss= 2.317754 acc= 0.382819 cost_time= 0.292208s \n",
      "Epoch:   4740 loss= 3.293688 acc= 0.440867 cost_time= 0.292302s \n",
      "Epoch:   4750 loss= 2.845456 acc= 0.343082 cost_time= 0.294785s \n",
      "Epoch:   4760 loss= 3.386268 acc= 0.408830 cost_time= 0.295110s \n",
      "Epoch:   4770 loss= 3.613243 acc= 0.344072 cost_time= 0.294467s \n",
      "Epoch:   4780 loss= 2.934764 acc= 0.428826 cost_time= 0.292913s \n",
      "Epoch:   4790 loss= 2.982891 acc= 0.373017 cost_time= 0.293357s \n",
      "Epoch:   4800 loss= 2.904976 acc= 0.364435 cost_time= 0.292082s \n",
      "Epoch:   4810 loss= 2.892535 acc= 0.473636 cost_time= 0.295291s \n",
      "Epoch:   4820 loss= 3.370654 acc= 0.329438 cost_time= 0.294852s \n",
      "Epoch:   4830 loss= 2.798082 acc= 0.511773 cost_time= 0.294444s \n",
      "Epoch:   4840 loss= 2.708652 acc= 0.400317 cost_time= 0.293293s \n",
      "Epoch:   4850 loss= 2.692128 acc= 0.455548 cost_time= 0.292240s \n",
      "Epoch:   4860 loss= 3.343851 acc= 0.382408 cost_time= 0.294834s \n",
      "Epoch:   4870 loss= 2.601341 acc= 0.474146 cost_time= 0.294075s \n",
      "Epoch:   4880 loss= 2.508431 acc= 0.385068 cost_time= 0.294763s \n",
      "Epoch:   4890 loss= 2.434601 acc= 0.506047 cost_time= 0.295530s \n",
      "Epoch:   4900 loss= 3.277747 acc= 0.416375 cost_time= 0.294531s \n",
      "Epoch:   4910 loss= 3.413175 acc= 0.399764 cost_time= 0.293135s \n",
      "Epoch:   4920 loss= 3.077860 acc= 0.425225 cost_time= 0.293792s \n",
      "Epoch:   4930 loss= 2.909883 acc= 0.459397 cost_time= 0.292173s \n",
      "Epoch:   4940 loss= 3.614541 acc= 0.319056 cost_time= 0.295056s \n",
      "Epoch:   4950 loss= 2.398934 acc= 0.408345 cost_time= 0.291777s \n",
      "Epoch:   4960 loss= 2.977277 acc= 0.417395 cost_time= 0.294778s \n",
      "Epoch:   4970 loss= 3.216570 acc= 0.308904 cost_time= 0.295396s \n",
      "Epoch:   4980 loss= 3.174910 acc= 0.350785 cost_time= 0.294767s \n",
      "Epoch:   4990 loss= 3.690411 acc= 0.413550 cost_time= 0.294768s \n",
      "Epoch:   5000 loss= 3.228820 acc= 0.348660 cost_time= 0.293409s \n",
      "Epoch:   5010 loss= 2.623120 acc= 0.427976 cost_time= 0.295594s \n",
      "Epoch:   5020 loss= 3.274047 acc= 0.390900 cost_time= 0.294461s \n",
      "Epoch:   5030 loss= 2.579757 acc= 0.458549 cost_time= 0.292545s \n",
      "Epoch:   5040 loss= 3.116203 acc= 0.445110 cost_time= 0.292624s \n",
      "Epoch:   5050 loss= 2.964937 acc= 0.382612 cost_time= 0.292586s \n",
      "Epoch:   5060 loss= 2.734149 acc= 0.375458 cost_time= 0.293687s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5070 loss= 2.405559 acc= 0.484845 cost_time= 0.290286s \n",
      "Epoch:   5080 loss= 2.706583 acc= 0.459701 cost_time= 0.292742s \n",
      "Epoch:   5090 loss= 2.548889 acc= 0.296693 cost_time= 0.294666s \n",
      "Epoch:   5100 loss= 2.877254 acc= 0.395662 cost_time= 0.293371s \n",
      "Epoch:   5110 loss= 2.959102 acc= 0.360770 cost_time= 0.292845s \n",
      "Epoch:   5120 loss= 2.917166 acc= 0.343243 cost_time= 0.293205s \n",
      "Epoch:   5130 loss= 2.800733 acc= 0.520124 cost_time= 0.294775s \n",
      "Epoch:   5140 loss= 3.248742 acc= 0.458439 cost_time= 0.294126s \n",
      "Epoch:   5150 loss= 2.830527 acc= 0.425940 cost_time= 0.295162s \n",
      "Epoch:   5160 loss= 2.516244 acc= 0.450156 cost_time= 0.293221s \n",
      "Epoch:   5170 loss= 2.919818 acc= 0.436374 cost_time= 0.294253s \n",
      "Epoch:   5180 loss= 3.287544 acc= 0.463799 cost_time= 0.295559s \n",
      "Epoch:   5190 loss= 3.135843 acc= 0.416584 cost_time= 0.293844s \n",
      "Epoch:   5200 loss= 3.184018 acc= 0.474421 cost_time= 0.293306s \n",
      "Epoch:   5210 loss= 2.395758 acc= 0.384906 cost_time= 0.299511s \n",
      "Epoch:   5220 loss= 2.447308 acc= 0.491914 cost_time= 0.290399s \n",
      "Epoch:   5230 loss= 3.265025 acc= 0.383310 cost_time= 0.294296s \n",
      "Epoch:   5240 loss= 3.240161 acc= 0.447877 cost_time= 0.292302s \n",
      "Epoch:   5250 loss= 2.561306 acc= 0.370172 cost_time= 0.293947s \n",
      "Epoch:   5260 loss= 2.932374 acc= 0.463083 cost_time= 0.292538s \n",
      "Epoch:   5270 loss= 2.693090 acc= 0.501318 cost_time= 0.292022s \n",
      "Epoch:   5280 loss= 3.151906 acc= 0.430152 cost_time= 0.294577s \n",
      "Epoch:   5290 loss= 2.880750 acc= 0.361501 cost_time= 0.292817s \n",
      "Epoch:   5300 loss= 3.063063 acc= 0.398684 cost_time= 0.293876s \n",
      "Epoch:   5310 loss= 3.311108 acc= 0.367812 cost_time= 0.295383s \n",
      "Epoch:   5320 loss= 2.943408 acc= 0.398058 cost_time= 0.291958s \n",
      "Epoch:   5330 loss= 3.313017 acc= 0.376395 cost_time= 0.292593s \n",
      "Epoch:   5340 loss= 2.756483 acc= 0.461511 cost_time= 0.293518s \n",
      "Epoch:   5350 loss= 2.893878 acc= 0.490461 cost_time= 0.293704s \n",
      "Epoch:   5360 loss= 2.320496 acc= 0.500336 cost_time= 0.293789s \n",
      "Epoch:   5370 loss= 3.098572 acc= 0.460955 cost_time= 0.294078s \n",
      "Epoch:   5380 loss= 3.509271 acc= 0.333621 cost_time= 0.293931s \n",
      "Epoch:   5390 loss= 2.509443 acc= 0.343360 cost_time= 0.292088s \n",
      "Epoch:   5400 loss= 2.719724 acc= 0.365996 cost_time= 0.292953s \n",
      "Epoch:   5410 loss= 2.833398 acc= 0.483006 cost_time= 0.295175s \n",
      "Epoch:   5420 loss= 3.503114 acc= 0.418480 cost_time= 0.294922s \n",
      "Epoch:   5430 loss= 2.830510 acc= 0.470663 cost_time= 0.297683s \n",
      "Epoch:   5440 loss= 3.061833 acc= 0.474961 cost_time= 0.296283s \n",
      "Epoch:   5450 loss= 2.836190 acc= 0.470282 cost_time= 0.293172s \n",
      "Epoch:   5460 loss= 2.655595 acc= 0.460412 cost_time= 0.295388s \n",
      "Epoch:   5470 loss= 3.075279 acc= 0.393240 cost_time= 0.292356s \n",
      "Epoch:   5480 loss= 2.610691 acc= 0.512376 cost_time= 0.293049s \n",
      "Epoch:   5490 loss= 2.976953 acc= 0.360864 cost_time= 0.294737s \n",
      "Epoch:   5500 loss= 3.359614 acc= 0.420120 cost_time= 0.293875s \n",
      "Epoch:   5510 loss= 3.194623 acc= 0.437888 cost_time= 0.293747s \n",
      "Epoch:   5520 loss= 2.915616 acc= 0.484370 cost_time= 0.294661s \n",
      "Epoch:   5530 loss= 2.850789 acc= 0.402977 cost_time= 0.293499s \n",
      "Epoch:   5540 loss= 2.633067 acc= 0.467702 cost_time= 0.294487s \n",
      "Epoch:   5550 loss= 2.321276 acc= 0.373092 cost_time= 0.294245s \n",
      "Epoch:   5560 loss= 2.737374 acc= 0.454564 cost_time= 0.295390s \n",
      "Epoch:   5570 loss= 2.989085 acc= 0.458800 cost_time= 0.293070s \n",
      "Epoch:   5580 loss= 2.620322 acc= 0.528378 cost_time= 0.295294s \n",
      "Epoch:   5590 loss= 2.960638 acc= 0.353969 cost_time= 0.294498s \n",
      "Epoch:   5600 loss= 3.104036 acc= 0.336073 cost_time= 0.292434s \n",
      "Epoch:   5610 loss= 2.631812 acc= 0.366383 cost_time= 0.298785s \n",
      "Epoch:   5620 loss= 2.156162 acc= 0.511491 cost_time= 0.291334s \n",
      "Epoch:   5630 loss= 2.846767 acc= 0.435466 cost_time= 0.293584s \n",
      "Epoch:   5640 loss= 2.911633 acc= 0.447304 cost_time= 0.294396s \n",
      "Epoch:   5650 loss= 2.923989 acc= 0.471353 cost_time= 0.294287s \n",
      "Epoch:   5660 loss= 2.971375 acc= 0.465486 cost_time= 0.293076s \n",
      "Epoch:   5670 loss= 3.194934 acc= 0.348553 cost_time= 0.292936s \n",
      "Epoch:   5680 loss= 3.167536 acc= 0.466330 cost_time= 0.292939s \n",
      "Epoch:   5690 loss= 3.195168 acc= 0.403376 cost_time= 0.295031s \n",
      "Epoch:   5700 loss= 3.075980 acc= 0.399673 cost_time= 0.292622s \n",
      "Epoch:   5710 loss= 2.628881 acc= 0.499109 cost_time= 0.294194s \n",
      "Epoch:   5720 loss= 2.811020 acc= 0.466657 cost_time= 0.293413s \n",
      "Epoch:   5730 loss= 2.975541 acc= 0.402163 cost_time= 0.294111s \n",
      "Epoch:   5740 loss= 2.868619 acc= 0.447240 cost_time= 0.296376s \n",
      "Epoch:   5750 loss= 3.005223 acc= 0.460288 cost_time= 0.293451s \n",
      "Epoch:   5760 loss= 2.550251 acc= 0.431314 cost_time= 0.292971s \n",
      "Epoch:   5770 loss= 2.655635 acc= 0.421485 cost_time= 0.294806s \n",
      "Epoch:   5780 loss= 2.848699 acc= 0.474789 cost_time= 0.295195s \n",
      "Epoch:   5790 loss= 2.895572 acc= 0.485309 cost_time= 0.293978s \n",
      "Epoch:   5800 loss= 2.587703 acc= 0.450467 cost_time= 0.294638s \n",
      "Epoch:   5810 loss= 2.426576 acc= 0.477443 cost_time= 0.294016s \n",
      "Epoch:   5820 loss= 3.156056 acc= 0.468781 cost_time= 0.293433s \n",
      "Epoch:   5830 loss= 3.108371 acc= 0.426163 cost_time= 0.291018s \n",
      "Epoch:   5840 loss= 2.965002 acc= 0.480624 cost_time= 0.290775s \n",
      "Epoch:   5850 loss= 3.263844 acc= 0.439031 cost_time= 0.296213s \n",
      "Epoch:   5860 loss= 2.820965 acc= 0.446022 cost_time= 0.290390s \n",
      "Epoch:   5870 loss= 2.968369 acc= 0.457118 cost_time= 0.295646s \n",
      "Epoch:   5880 loss= 3.460248 acc= 0.425933 cost_time= 0.295097s \n",
      "Epoch:   5890 loss= 3.096920 acc= 0.485115 cost_time= 0.292138s \n",
      "Epoch:   5900 loss= 3.113705 acc= 0.440292 cost_time= 0.291649s \n",
      "Epoch:   5910 loss= 3.003518 acc= 0.417058 cost_time= 0.294270s \n",
      "Epoch:   5920 loss= 2.972143 acc= 0.511305 cost_time= 0.293598s \n",
      "Epoch:   5930 loss= 2.624022 acc= 0.432649 cost_time= 0.296009s \n",
      "Epoch:   5940 loss= 2.800312 acc= 0.416313 cost_time= 0.291744s \n",
      "Epoch:   5950 loss= 3.165951 acc= 0.388301 cost_time= 0.296722s \n",
      "Epoch:   5960 loss= 2.143121 acc= 0.462188 cost_time= 0.292943s \n",
      "Epoch:   5970 loss= 3.197147 acc= 0.407020 cost_time= 0.292405s \n",
      "Epoch:   5980 loss= 2.504580 acc= 0.362156 cost_time= 0.292141s \n",
      "Epoch:   5990 loss= 2.630687 acc= 0.342399 cost_time= 0.290183s \n",
      "Epoch:   6000 loss= 2.852828 acc= 0.416696 cost_time= 0.292453s \n",
      "Epoch:   6010 loss= 2.335566 acc= 0.424547 cost_time= 0.294249s \n",
      "Epoch:   6020 loss= 3.112932 acc= 0.374575 cost_time= 0.292849s \n",
      "Epoch:   6030 loss= 2.606572 acc= 0.432353 cost_time= 0.290911s \n",
      "Epoch:   6040 loss= 2.650449 acc= 0.516633 cost_time= 0.293576s \n",
      "Epoch:   6050 loss= 3.360592 acc= 0.430616 cost_time= 0.294579s \n",
      "Epoch:   6060 loss= 2.804805 acc= 0.480116 cost_time= 0.296004s \n",
      "Epoch:   6070 loss= 3.445966 acc= 0.427296 cost_time= 0.296850s \n",
      "Epoch:   6080 loss= 2.976648 acc= 0.429183 cost_time= 0.292026s \n",
      "Epoch:   6090 loss= 3.162632 acc= 0.364420 cost_time= 0.293319s \n",
      "Epoch:   6100 loss= 2.680548 acc= 0.453111 cost_time= 0.293765s \n",
      "Epoch:   6110 loss= 2.419978 acc= 0.406971 cost_time= 0.291051s \n",
      "Epoch:   6120 loss= 2.549692 acc= 0.517618 cost_time= 0.293959s \n",
      "Epoch:   6130 loss= 3.048995 acc= 0.306105 cost_time= 0.295716s \n",
      "Epoch:   6140 loss= 3.151982 acc= 0.404348 cost_time= 0.293769s \n",
      "Epoch:   6150 loss= 2.770456 acc= 0.345603 cost_time= 0.294474s \n",
      "Epoch:   6160 loss= 2.889435 acc= 0.419856 cost_time= 0.292716s \n",
      "Epoch:   6170 loss= 2.802577 acc= 0.486630 cost_time= 0.294283s \n",
      "Epoch:   6180 loss= 3.276724 acc= 0.449175 cost_time= 0.295376s \n",
      "Epoch:   6190 loss= 3.008167 acc= 0.459177 cost_time= 0.292883s \n",
      "Epoch:   6200 loss= 2.769438 acc= 0.350619 cost_time= 0.293829s \n",
      "Epoch:   6210 loss= 3.278350 acc= 0.524240 cost_time= 0.294141s \n",
      "Epoch:   6220 loss= 2.858036 acc= 0.477405 cost_time= 0.293702s \n",
      "Epoch:   6230 loss= 2.228751 acc= 0.503890 cost_time= 0.294366s \n",
      "Epoch:   6240 loss= 2.722250 acc= 0.497832 cost_time= 0.293350s \n",
      "Epoch:   6250 loss= 2.927395 acc= 0.427274 cost_time= 0.293323s \n",
      "Epoch:   6260 loss= 2.973361 acc= 0.499618 cost_time= 0.293298s \n",
      "Epoch:   6270 loss= 3.059197 acc= 0.436911 cost_time= 0.296623s \n",
      "Epoch:   6280 loss= 2.794296 acc= 0.384898 cost_time= 0.291025s \n",
      "Epoch:   6290 loss= 2.227278 acc= 0.442927 cost_time= 0.291554s \n",
      "Epoch:   6300 loss= 2.868092 acc= 0.448989 cost_time= 0.293730s \n",
      "Epoch:   6310 loss= 2.602028 acc= 0.500914 cost_time= 0.293464s \n",
      "Epoch:   6320 loss= 3.055171 acc= 0.424814 cost_time= 0.292074s \n",
      "Epoch:   6330 loss= 2.076020 acc= 0.454453 cost_time= 0.295799s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6340 loss= 2.577924 acc= 0.377623 cost_time= 0.289723s \n",
      "Epoch:   6350 loss= 3.017995 acc= 0.439417 cost_time= 0.291662s \n",
      "Epoch:   6360 loss= 2.756611 acc= 0.448071 cost_time= 0.291592s \n",
      "Epoch:   6370 loss= 2.497851 acc= 0.446712 cost_time= 0.293399s \n",
      "Epoch:   6380 loss= 2.609798 acc= 0.439608 cost_time= 0.297437s \n",
      "Epoch:   6390 loss= 2.761481 acc= 0.491099 cost_time= 0.291031s \n",
      "Epoch:   6400 loss= 2.395180 acc= 0.511724 cost_time= 0.293327s \n",
      "Epoch:   6410 loss= 2.572374 acc= 0.532840 cost_time= 0.291673s \n",
      "Epoch:   6420 loss= 2.752583 acc= 0.417124 cost_time= 0.291083s \n",
      "Epoch:   6430 loss= 2.673844 acc= 0.455241 cost_time= 0.294235s \n",
      "Epoch:   6440 loss= 2.748278 acc= 0.440416 cost_time= 0.292005s \n",
      "Epoch:   6450 loss= 3.357193 acc= 0.405035 cost_time= 0.295229s \n",
      "Epoch:   6460 loss= 2.672375 acc= 0.358994 cost_time= 0.293393s \n",
      "Epoch:   6470 loss= 2.488067 acc= 0.504140 cost_time= 0.292814s \n",
      "Epoch:   6480 loss= 3.371945 acc= 0.416084 cost_time= 0.294279s \n",
      "Epoch:   6490 loss= 2.548013 acc= 0.494277 cost_time= 0.289385s \n",
      "Epoch:   6500 loss= 3.016391 acc= 0.358356 cost_time= 0.294781s \n",
      "Epoch:   6510 loss= 2.790565 acc= 0.506090 cost_time= 0.296263s \n",
      "Epoch:   6520 loss= 2.421951 acc= 0.544849 cost_time= 0.291263s \n",
      "Epoch:   6530 loss= 3.026649 acc= 0.462041 cost_time= 0.297468s \n",
      "Epoch:   6540 loss= 3.340208 acc= 0.452853 cost_time= 0.294676s \n",
      "Epoch:   6550 loss= 2.959446 acc= 0.340709 cost_time= 0.292655s \n",
      "Epoch:   6560 loss= 2.906739 acc= 0.411457 cost_time= 0.294350s \n",
      "Epoch:   6570 loss= 2.678671 acc= 0.458694 cost_time= 0.292876s \n",
      "Epoch:   6580 loss= 3.201389 acc= 0.452158 cost_time= 0.296582s \n",
      "Epoch:   6590 loss= 2.770513 acc= 0.454400 cost_time= 0.293476s \n",
      "Epoch:   6600 loss= 3.122318 acc= 0.358724 cost_time= 0.294532s \n",
      "Epoch:   6610 loss= 2.203110 acc= 0.446653 cost_time= 0.295083s \n",
      "Epoch:   6620 loss= 2.549213 acc= 0.616750 cost_time= 0.291409s \n",
      "Epoch:   6630 loss= 2.882404 acc= 0.479241 cost_time= 0.295443s \n",
      "Epoch:   6640 loss= 2.285012 acc= 0.476101 cost_time= 0.292227s \n",
      "Epoch:   6650 loss= 2.399228 acc= 0.507894 cost_time= 0.293140s \n",
      "Epoch:   6660 loss= 3.154975 acc= 0.413513 cost_time= 0.294856s \n",
      "Epoch:   6670 loss= 3.447635 acc= 0.413934 cost_time= 0.296287s \n",
      "Epoch:   6680 loss= 3.167329 acc= 0.339723 cost_time= 0.292586s \n",
      "Epoch:   6690 loss= 3.081177 acc= 0.442889 cost_time= 0.295186s \n",
      "Epoch:   6700 loss= 2.833061 acc= 0.460152 cost_time= 0.293167s \n",
      "Epoch:   6710 loss= 3.269392 acc= 0.336688 cost_time= 0.293638s \n",
      "Epoch:   6720 loss= 2.637999 acc= 0.547104 cost_time= 0.294587s \n",
      "Epoch:   6730 loss= 2.780993 acc= 0.426129 cost_time= 0.293037s \n",
      "Epoch:   6740 loss= 2.975954 acc= 0.482659 cost_time= 0.292725s \n",
      "Epoch:   6750 loss= 3.306965 acc= 0.344330 cost_time= 0.290700s \n",
      "Epoch:   6760 loss= 3.135022 acc= 0.463245 cost_time= 0.293231s \n",
      "Epoch:   6770 loss= 3.093563 acc= 0.393892 cost_time= 0.293407s \n",
      "Epoch:   6780 loss= 2.656236 acc= 0.435625 cost_time= 0.292391s \n",
      "Epoch:   6790 loss= 2.632732 acc= 0.379668 cost_time= 0.293246s \n",
      "Epoch:   6800 loss= 2.544823 acc= 0.404501 cost_time= 0.293145s \n",
      "Epoch:   6810 loss= 3.060525 acc= 0.340508 cost_time= 0.294076s \n",
      "Epoch:   6820 loss= 3.600800 acc= 0.477556 cost_time= 0.294139s \n",
      "Epoch:   6830 loss= 2.880818 acc= 0.503273 cost_time= 0.293750s \n",
      "Epoch:   6840 loss= 2.449252 acc= 0.483601 cost_time= 0.293235s \n",
      "Epoch:   6850 loss= 2.745586 acc= 0.437153 cost_time= 0.293681s \n",
      "Epoch:   6860 loss= 3.067414 acc= 0.473436 cost_time= 0.293336s \n",
      "Epoch:   6870 loss= 3.212211 acc= 0.452194 cost_time= 0.294157s \n",
      "Epoch:   6880 loss= 2.882799 acc= 0.454334 cost_time= 0.292731s \n",
      "Epoch:   6890 loss= 3.065168 acc= 0.459885 cost_time= 0.291183s \n",
      "Epoch:   6900 loss= 2.727099 acc= 0.486595 cost_time= 0.296938s \n",
      "Epoch:   6910 loss= 2.808906 acc= 0.475908 cost_time= 0.308435s \n",
      "Epoch:   6920 loss= 2.807075 acc= 0.451334 cost_time= 0.308788s \n",
      "Epoch:   6930 loss= 2.833917 acc= 0.387747 cost_time= 0.304291s \n",
      "Epoch:   6940 loss= 2.758125 acc= 0.577884 cost_time= 0.308722s \n",
      "Epoch:   6950 loss= 3.406723 acc= 0.371999 cost_time= 0.304297s \n",
      "Epoch:   6960 loss= 2.842813 acc= 0.449719 cost_time= 0.301149s \n",
      "Epoch:   6970 loss= 3.095138 acc= 0.466158 cost_time= 0.300671s \n",
      "Epoch:   6980 loss= 3.021741 acc= 0.488903 cost_time= 0.305256s \n",
      "Epoch:   6990 loss= 3.458441 acc= 0.361165 cost_time= 0.302146s \n",
      "Epoch:   7000 loss= 2.740558 acc= 0.435896 cost_time= 0.298524s \n",
      "Epoch:   7010 loss= 2.932505 acc= 0.437132 cost_time= 0.302949s \n",
      "Epoch:   7020 loss= 2.738940 acc= 0.416862 cost_time= 0.300975s \n",
      "Epoch:   7030 loss= 2.920840 acc= 0.418083 cost_time= 0.300687s \n",
      "Epoch:   7040 loss= 2.914659 acc= 0.469454 cost_time= 0.299299s \n",
      "Epoch:   7050 loss= 2.869891 acc= 0.403911 cost_time= 0.298970s \n",
      "Epoch:   7060 loss= 3.123612 acc= 0.445886 cost_time= 0.299474s \n",
      "Epoch:   7070 loss= 2.758041 acc= 0.510347 cost_time= 0.299950s \n",
      "Epoch:   7080 loss= 2.874680 acc= 0.421882 cost_time= 0.298582s \n",
      "Epoch:   7090 loss= 2.388035 acc= 0.422738 cost_time= 0.299607s \n",
      "Epoch:   7100 loss= 2.487592 acc= 0.493672 cost_time= 0.300998s \n",
      "Epoch:   7110 loss= 2.808887 acc= 0.361822 cost_time= 0.302401s \n",
      "Epoch:   7120 loss= 3.204863 acc= 0.407431 cost_time= 0.300048s \n",
      "Epoch:   7130 loss= 3.209891 acc= 0.469172 cost_time= 0.300007s \n",
      "Epoch:   7140 loss= 3.186543 acc= 0.497496 cost_time= 0.302132s \n",
      "Epoch:   7150 loss= 2.730809 acc= 0.470056 cost_time= 0.301112s \n",
      "Epoch:   7160 loss= 3.306192 acc= 0.442878 cost_time= 0.299194s \n",
      "Epoch:   7170 loss= 2.673896 acc= 0.480438 cost_time= 0.298337s \n",
      "Epoch:   7180 loss= 1.851717 acc= 0.409400 cost_time= 0.296916s \n",
      "Epoch:   7190 loss= 3.680431 acc= 0.385158 cost_time= 0.299489s \n",
      "Epoch:   7200 loss= 2.529383 acc= 0.519843 cost_time= 0.301740s \n",
      "Epoch:   7210 loss= 2.936304 acc= 0.400138 cost_time= 0.300622s \n",
      "Epoch:   7220 loss= 3.384651 acc= 0.317507 cost_time= 0.297948s \n",
      "Epoch:   7230 loss= 2.683030 acc= 0.535462 cost_time= 0.300617s \n",
      "Epoch:   7240 loss= 2.728981 acc= 0.455563 cost_time= 0.299174s \n",
      "Epoch:   7250 loss= 2.799374 acc= 0.463357 cost_time= 0.297385s \n",
      "Epoch:   7260 loss= 2.647292 acc= 0.340299 cost_time= 0.298301s \n",
      "Epoch:   7270 loss= 3.255801 acc= 0.387493 cost_time= 0.300332s \n",
      "Epoch:   7280 loss= 2.386066 acc= 0.456708 cost_time= 0.302423s \n",
      "Epoch:   7290 loss= 3.067719 acc= 0.416943 cost_time= 0.298885s \n",
      "Epoch:   7300 loss= 2.482255 acc= 0.523193 cost_time= 0.301043s \n",
      "Epoch:   7310 loss= 3.402853 acc= 0.376893 cost_time= 0.299191s \n",
      "Epoch:   7320 loss= 3.092706 acc= 0.476416 cost_time= 0.305046s \n",
      "Epoch:   7330 loss= 2.966783 acc= 0.513540 cost_time= 0.301649s \n",
      "Epoch:   7340 loss= 3.426537 acc= 0.371828 cost_time= 0.299662s \n",
      "Epoch:   7350 loss= 2.285836 acc= 0.607864 cost_time= 0.300916s \n",
      "Epoch:   7360 loss= 2.508742 acc= 0.490823 cost_time= 0.298930s \n",
      "Epoch:   7370 loss= 3.188544 acc= 0.353349 cost_time= 0.297718s \n",
      "Epoch:   7380 loss= 2.505327 acc= 0.488421 cost_time= 0.300850s \n",
      "Epoch:   7390 loss= 2.235081 acc= 0.490289 cost_time= 0.303536s \n",
      "Epoch:   7400 loss= 2.887824 acc= 0.352123 cost_time= 0.301297s \n",
      "Epoch:   7410 loss= 2.361799 acc= 0.452011 cost_time= 0.297483s \n",
      "Epoch:   7420 loss= 2.856489 acc= 0.496751 cost_time= 0.304541s \n",
      "Epoch:   7430 loss= 2.914337 acc= 0.392273 cost_time= 0.301126s \n",
      "Epoch:   7440 loss= 2.456463 acc= 0.468961 cost_time= 0.300545s \n",
      "Epoch:   7450 loss= 3.045760 acc= 0.477682 cost_time= 0.303658s \n",
      "Epoch:   7460 loss= 2.781712 acc= 0.458470 cost_time= 0.296643s \n",
      "Epoch:   7470 loss= 2.898594 acc= 0.464856 cost_time= 0.301447s \n",
      "Epoch:   7480 loss= 3.570347 acc= 0.355396 cost_time= 0.299665s \n",
      "Epoch:   7490 loss= 2.887311 acc= 0.455499 cost_time= 0.297350s \n",
      "Epoch:   7500 loss= 2.647826 acc= 0.395198 cost_time= 0.298557s \n",
      "Epoch:   7510 loss= 2.407359 acc= 0.516015 cost_time= 0.302898s \n",
      "Epoch:   7520 loss= 3.234447 acc= 0.444616 cost_time= 0.296746s \n",
      "Epoch:   7530 loss= 2.274523 acc= 0.494485 cost_time= 0.299773s \n",
      "Epoch:   7540 loss= 2.465694 acc= 0.446017 cost_time= 0.298538s \n",
      "Epoch:   7550 loss= 2.431126 acc= 0.497490 cost_time= 0.303130s \n",
      "Epoch:   7560 loss= 2.593916 acc= 0.522189 cost_time= 0.298309s \n",
      "Epoch:   7570 loss= 2.917326 acc= 0.459098 cost_time= 0.301907s \n",
      "Epoch:   7580 loss= 2.723010 acc= 0.456831 cost_time= 0.298337s \n",
      "Epoch:   7590 loss= 2.482672 acc= 0.456217 cost_time= 0.298434s \n",
      "Epoch:   7600 loss= 2.470176 acc= 0.518251 cost_time= 0.297303s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7610 loss= 3.571800 acc= 0.382528 cost_time= 0.298999s \n",
      "Epoch:   7620 loss= 2.786482 acc= 0.549331 cost_time= 0.300283s \n",
      "Epoch:   7630 loss= 2.783864 acc= 0.371253 cost_time= 0.298307s \n",
      "Epoch:   7640 loss= 3.326617 acc= 0.463848 cost_time= 0.296359s \n",
      "Epoch:   7650 loss= 3.197373 acc= 0.466053 cost_time= 0.301017s \n",
      "Epoch:   7660 loss= 2.905536 acc= 0.416620 cost_time= 0.298686s \n",
      "Epoch:   7670 loss= 2.851274 acc= 0.490687 cost_time= 0.297957s \n",
      "Epoch:   7680 loss= 2.977463 acc= 0.424272 cost_time= 0.303935s \n",
      "Epoch:   7690 loss= 2.443136 acc= 0.486226 cost_time= 0.320939s \n",
      "Epoch:   7700 loss= 3.029971 acc= 0.484449 cost_time= 0.322021s \n",
      "Epoch:   7710 loss= 2.742077 acc= 0.394991 cost_time= 0.299976s \n",
      "Epoch:   7720 loss= 3.138247 acc= 0.377642 cost_time= 0.302428s \n",
      "Epoch:   7730 loss= 3.100246 acc= 0.419501 cost_time= 0.298398s \n",
      "Epoch:   7740 loss= 3.276858 acc= 0.401829 cost_time= 0.300558s \n",
      "Epoch:   7750 loss= 2.546143 acc= 0.475023 cost_time= 0.300143s \n",
      "Epoch:   7760 loss= 3.376222 acc= 0.524835 cost_time= 0.300415s \n",
      "Epoch:   7770 loss= 2.676715 acc= 0.527990 cost_time= 0.302552s \n",
      "Epoch:   7780 loss= 2.629221 acc= 0.498471 cost_time= 0.303058s \n",
      "Epoch:   7790 loss= 3.209855 acc= 0.377677 cost_time= 0.302118s \n",
      "Epoch:   7800 loss= 2.961139 acc= 0.458762 cost_time= 0.304494s \n",
      "Epoch:   7810 loss= 2.907706 acc= 0.462845 cost_time= 0.301827s \n",
      "Epoch:   7820 loss= 2.531381 acc= 0.448784 cost_time= 0.302493s \n",
      "Epoch:   7830 loss= 3.526485 acc= 0.373451 cost_time= 0.300561s \n",
      "Epoch:   7840 loss= 3.161228 acc= 0.393633 cost_time= 0.302641s \n",
      "Epoch:   7850 loss= 3.141724 acc= 0.408780 cost_time= 0.301144s \n",
      "Epoch:   7860 loss= 2.678509 acc= 0.488595 cost_time= 0.302899s \n",
      "Epoch:   7870 loss= 2.498910 acc= 0.438879 cost_time= 0.307382s \n",
      "Epoch:   7880 loss= 2.690975 acc= 0.455184 cost_time= 0.301595s \n",
      "Epoch:   7890 loss= 2.437063 acc= 0.492243 cost_time= 0.306258s \n",
      "Epoch:   7900 loss= 2.820969 acc= 0.474787 cost_time= 0.304322s \n",
      "Epoch:   7910 loss= 2.860372 acc= 0.476251 cost_time= 0.300511s \n",
      "Epoch:   7920 loss= 3.167068 acc= 0.504408 cost_time= 0.307179s \n",
      "Epoch:   7930 loss= 3.102817 acc= 0.436836 cost_time= 0.302944s \n",
      "Epoch:   7940 loss= 2.788310 acc= 0.455403 cost_time= 0.304642s \n",
      "Epoch:   7950 loss= 2.660509 acc= 0.387203 cost_time= 0.306988s \n",
      "Epoch:   7960 loss= 2.390709 acc= 0.596188 cost_time= 0.308541s \n",
      "Epoch:   7970 loss= 3.156713 acc= 0.385831 cost_time= 0.306599s \n",
      "Epoch:   7980 loss= 2.716471 acc= 0.454644 cost_time= 0.310519s \n",
      "Epoch:   7990 loss= 2.692846 acc= 0.447886 cost_time= 0.307156s \n",
      "Epoch:   8000 loss= 3.600255 acc= 0.366416 cost_time= 0.306673s \n",
      "Epoch:   8010 loss= 2.494206 acc= 0.430314 cost_time= 0.304696s \n",
      "Epoch:   8020 loss= 3.132781 acc= 0.352863 cost_time= 0.304608s \n",
      "Epoch:   8030 loss= 2.589333 acc= 0.384336 cost_time= 0.305816s \n",
      "Epoch:   8040 loss= 3.063652 acc= 0.462333 cost_time= 0.306824s \n",
      "Epoch:   8050 loss= 2.493430 acc= 0.509814 cost_time= 0.307727s \n",
      "Epoch:   8060 loss= 3.180889 acc= 0.416662 cost_time= 0.305898s \n",
      "Epoch:   8070 loss= 2.590630 acc= 0.384922 cost_time= 0.306763s \n",
      "Epoch:   8080 loss= 3.285193 acc= 0.344131 cost_time= 0.320196s \n",
      "Epoch:   8090 loss= 2.705574 acc= 0.490248 cost_time= 0.305601s \n",
      "Epoch:   8100 loss= 3.194655 acc= 0.321804 cost_time= 0.308842s \n",
      "Epoch:   8110 loss= 2.597019 acc= 0.487051 cost_time= 0.313244s \n",
      "Epoch:   8120 loss= 2.368089 acc= 0.468425 cost_time= 0.519822s \n",
      "Epoch:   8130 loss= 2.940468 acc= 0.404440 cost_time= 0.378510s \n",
      "Epoch:   8140 loss= 2.421325 acc= 0.437562 cost_time= 0.348508s \n",
      "Epoch:   8150 loss= 2.859085 acc= 0.413161 cost_time= 0.408126s \n",
      "Epoch:   8160 loss= 2.539895 acc= 0.470260 cost_time= 0.546171s \n",
      "Epoch:   8170 loss= 2.610974 acc= 0.489660 cost_time= 0.509117s \n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    # sess init or restore\n",
    "    if weights_path is None:\n",
    "        log.info('Training from scratch')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # read vgg model\n",
    "        pretrained_weights = np.load('./data/vgg16.npy', encoding='latin1').item()\n",
    "        for vv in tf.trainable_variables():\n",
    "            weights_key = vv.name.split('/')[-3]\n",
    "            try:\n",
    "                weights = pretrained_weights[weights_key][0]\n",
    "                _op = tf.assign(vv, weights)\n",
    "                sess.run(_op)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    else:\n",
    "        log.info('Restore model from last model checkpoint {:s}'.format(weights_path))\n",
    "        # restore weights\n",
    "        saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "    # epoch loop\n",
    "    for epoch in range(CFG.TRAIN.EPOCHS):\n",
    "\n",
    "        # Use training data for optimization\n",
    "        for _ in range(CFG.TRAIN.NOOFBATCHES):\n",
    "            with tf.device('/cpu:0'):\n",
    "                gt_imgs, binary_gt_labels = train_dataset.next_batch(CFG.TRAIN.BATCH_SIZE)\n",
    "                gt_imgs, binary_gt_labels = resize_training_data(gt_imgs, binary_gt_labels)\n",
    "\n",
    "            sess.run(optimizer, feed_dict={input_tensor:gt_imgs, \n",
    "                                           binary_label:binary_gt_labels, \n",
    "                                           phase:'train'})\n",
    "\n",
    "        # Validate after every epoch\n",
    "        t_start = time.time()\n",
    "        with tf.device('/cpu:0'):\n",
    "            gt_imgs, binary_gt_labels = train_dataset.next_batch(CFG.TRAIN.BATCH_SIZE)\n",
    "            gt_imgs, binary_gt_labels = resize_training_data(gt_imgs, binary_gt_labels)\n",
    "\n",
    "        train_loss, train_accuracy, train_img, train_summary = \\\n",
    "            sess.run([loss, accuracy, out_logits_out, merged_summary_op],\n",
    "                     feed_dict={input_tensor: gt_imgs,\n",
    "                                binary_label: binary_gt_labels,\n",
    "                                phase: 'train'})\n",
    "\n",
    "        # time\n",
    "        cost_time = time.time() - t_start\n",
    "        train_cost_time_mean.append(cost_time)\n",
    "        \n",
    "        # summary\n",
    "        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n",
    "\n",
    "        # history\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES > 10:\n",
    "            history.append([train_loss, train_accuracy])\n",
    "\n",
    "        # progress\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 100 == 0:\n",
    "            print('Epoch: {:6d} loss= {:6f} acc= {:6f} cost_time= {:5f}s '.\n",
    "                  format(epoch, train_loss, train_accuracy, np.mean(train_cost_time_mean)))\n",
    "            train_cost_time_mean.clear()\n",
    "\n",
    "        # output image\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 100 == 0:\n",
    "            binary_seg_image_3ch = np.array([[[0]*3]*__C.TRAIN.IMG_WIDTH]*__C.TRAIN.IMG_HEIGHT, np.float64)\n",
    "            binary_seg_image_3ch[:, :, 0] = 0\n",
    "            binary_seg_image_3ch[:, :, 1] = 0\n",
    "            binary_seg_image_3ch[:, :, 2] = train_img[0][:, :]*255\n",
    "            image = gt_imgs[0] + VGG_MEAN\n",
    "            image_field2 = cv2.addWeighted(image, 1.0, binary_seg_image_3ch, 1.0, 0.0)\n",
    "            path = image_save_path + '/image_{:d}.png'.format(epoch)\n",
    "            cv2.imwrite(path, image_field2)\n",
    "\n",
    "        # store model\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 2000 == 0:\n",
    "            saver.save(sess=sess, save_path=model_save_path, global_step=epoch)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,15),dpi=100)\n",
    "ax1 = fig.add_subplot(2,1,1, facecolor='w')\n",
    "ax1.plot(np.arange(1, history.shape[0] + 1), history[:, 0], label='loss')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.arange(1, history.shape[0] + 1), history[:, 1], label='accuracy', color=cmap(1))\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
