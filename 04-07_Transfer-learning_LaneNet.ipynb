{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as ops\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import glog as log\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warning for tf 2.0\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Data Set and Weights Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/training_data_tusimple_bdd100k/'\n",
    "weights_path = 'model/tusimple_lanenet/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__C = edict()\n",
    "\n",
    "cfg = __C\n",
    "\n",
    "__C.TRAIN = edict()\n",
    "__C.TRAIN.EPOCHS = 10000\n",
    "__C.TRAIN.NOOFBATCHES = 10\n",
    "__C.TRAIN.MOMENTUM = 0.9\n",
    "__C.TRAIN.LEARNING_RATE = 0.0005\n",
    "__C.TRAIN.GPU_MEMORY_FRACTION = 0.85\n",
    "__C.TRAIN.TF_ALLOW_GROWTH = True\n",
    "__C.TRAIN.BATCH_SIZE = 8\n",
    "__C.TRAIN.IMG_HEIGHT = 256\n",
    "__C.TRAIN.IMG_WIDTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, dataset_info_file):\n",
    "        self._gt_img_list, self._gt_label_binary_list = self._init_dataset(dataset_info_file)\n",
    "        self._random_dataset()\n",
    "        self._next_batch_loop_count = 0\n",
    "\n",
    "    def _init_dataset(self, dataset_info_file):\n",
    "        gt_img_list = []\n",
    "        gt_label_binary_list = []\n",
    "\n",
    "        assert ops.exists(dataset_info_file), '{:s}ã€€does not exist'.format(dataset_info_file)\n",
    "\n",
    "        with open(dataset_info_file, 'r') as file:\n",
    "            for _info in file:\n",
    "                info_tmp = _info.strip(' ').split()\n",
    "\n",
    "                gt_img_list.append(info_tmp[0])\n",
    "                gt_label_binary_list.append(info_tmp[1])\n",
    "\n",
    "        return gt_img_list, gt_label_binary_list\n",
    "\n",
    "    def _random_dataset(self):\n",
    "        assert len(self._gt_img_list) == len(self._gt_label_binary_list)\n",
    "\n",
    "        random_idx = np.random.permutation(len(self._gt_img_list))\n",
    "        new_gt_img_list = []\n",
    "        new_gt_label_binary_list = []\n",
    "\n",
    "        for index in random_idx:\n",
    "            new_gt_img_list.append(self._gt_img_list[index])\n",
    "            new_gt_label_binary_list.append(self._gt_label_binary_list[index])\n",
    "\n",
    "        self._gt_img_list = new_gt_img_list\n",
    "        self._gt_label_binary_list = new_gt_label_binary_list\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        assert len(self._gt_label_binary_list) == len(self._gt_img_list)\n",
    "\n",
    "        idx_start = batch_size * self._next_batch_loop_count\n",
    "        idx_end = batch_size * self._next_batch_loop_count + batch_size\n",
    "\n",
    "        if idx_start == 0 and idx_end > len(self._gt_label_binary_list):\n",
    "            raise ValueError('Batch size cannot be larger than the total number of samples', \n",
    "                             idx_end, len(self._gt_label_binary_list))\n",
    "\n",
    "        if idx_end > len(self._gt_label_binary_list):\n",
    "            self._random_dataset()\n",
    "            self._next_batch_loop_count = 0\n",
    "            return self.next_batch(batch_size)\n",
    "        else:\n",
    "            gt_img_list = self._gt_img_list[idx_start:idx_end]\n",
    "            gt_label_binary_list = self._gt_label_binary_list[idx_start:idx_end]\n",
    "\n",
    "            gt_imgs = []\n",
    "            gt_labels_binary = []\n",
    "\n",
    "            for gt_img_path in gt_img_list:\n",
    "                gt_imgs.append(cv2.imread(gt_img_path, cv2.IMREAD_COLOR))\n",
    "\n",
    "            for gt_label_path in gt_label_binary_list:\n",
    "                label_img = cv2.imread(gt_label_path, cv2.IMREAD_COLOR)\n",
    "                label_binary = np.zeros([label_img.shape[0], label_img.shape[1]], dtype=np.uint8)\n",
    "                idx = np.where((label_img[:, :, :] != [0, 0, 0]).all(axis=2))\n",
    "                label_binary[idx] = 1\n",
    "                gt_labels_binary.append(label_binary)\n",
    "\n",
    "            self._next_batch_loop_count += 1\n",
    "\n",
    "        return gt_imgs, gt_labels_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_dataset_file = ops.join(dataset_dir, 'train.txt')\n",
    "assert ops.exists(train_dataset_file)\n",
    "train_dataset = DataSet(train_dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Base Function\n",
    "## cnn_basenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBaseModel(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def conv2d(inputdata, out_channel, kernel_size, padding='SAME',\n",
    "               stride=1, w_init=None, b_init=None,\n",
    "               split=1, use_bias=True, data_format='NHWC', name=None):\n",
    "        with tf.variable_scope(name):\n",
    "            in_shape = inputdata.get_shape().as_list()\n",
    "            channel_axis = 3 if data_format == 'NHWC' else 1\n",
    "            in_channel = in_shape[channel_axis]\n",
    "            assert in_channel is not None, \"[Conv2D] Input cannot have unknown channel!\"\n",
    "            assert in_channel % split == 0\n",
    "            assert out_channel % split == 0\n",
    "\n",
    "            padding = padding.upper()\n",
    "\n",
    "            if isinstance(kernel_size, list):\n",
    "                filter_shape = [kernel_size[0], kernel_size[1]] + [in_channel / split, out_channel]\n",
    "            else:\n",
    "                filter_shape = [kernel_size, kernel_size] + [in_channel / split, out_channel]\n",
    "\n",
    "            if isinstance(stride, list):\n",
    "                strides = [1, stride[0], stride[1], 1] if data_format == 'NHWC' \\\n",
    "                    else [1, 1, stride[0], stride[1]]\n",
    "            else:\n",
    "                strides = [1, stride, stride, 1] if data_format == 'NHWC' \\\n",
    "                    else [1, 1, stride, stride]\n",
    "\n",
    "            if w_init is None:\n",
    "                w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            if b_init is None:\n",
    "                b_init = tf.constant_initializer()\n",
    "\n",
    "            w = tf.get_variable('W', filter_shape, initializer=w_init)\n",
    "            b = None\n",
    "\n",
    "            if use_bias:\n",
    "                b = tf.get_variable('b', [out_channel], initializer=b_init)\n",
    "\n",
    "            if split == 1:\n",
    "                conv = tf.nn.conv2d(inputdata, w, strides, padding, data_format=data_format)\n",
    "            else:\n",
    "                inputs = tf.split(inputdata, split, channel_axis)\n",
    "                kernels = tf.split(w, split, 3)\n",
    "                outputs = [tf.nn.conv2d(i, k, strides, padding, data_format=data_format)\n",
    "                           for i, k in zip(inputs, kernels)]\n",
    "                conv = tf.concat(outputs, channel_axis)\n",
    "\n",
    "            ret = tf.identity(tf.nn.bias_add(conv, b, data_format=data_format) if use_bias else conv, name=name)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(inputdata, name=None):\n",
    "        return tf.nn.relu(features=inputdata, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def maxpooling(inputdata, kernel_size, stride=None, \\\n",
    "                   padding='VALID', data_format='NHWC', name=None):\n",
    "        padding = padding.upper()\n",
    "\n",
    "        if stride is None:\n",
    "            stride = kernel_size\n",
    "\n",
    "        if isinstance(kernel_size, list):\n",
    "            kernel = [1, kernel_size[0], kernel_size[1], 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, kernel_size[0], kernel_size[1]]\n",
    "        else:\n",
    "            kernel = [1, kernel_size, kernel_size, 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, kernel_size, kernel_size]\n",
    "\n",
    "        if isinstance(stride, list):\n",
    "            strides = [1, stride[0], stride[1], 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, stride[0], stride[1]]\n",
    "        else:\n",
    "            strides = [1, stride, stride, 1] if data_format == 'NHWC' \\\n",
    "                else [1, 1, stride, stride]\n",
    "\n",
    "        return tf.nn.max_pool(value=inputdata, ksize=kernel, strides=strides, \\\n",
    "                              padding=padding, data_format=data_format, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def layerbn(inputdata, is_training, name):\n",
    "        return tf.layers.batch_normalization(inputs=inputdata, training=is_training, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def deconv2d(inputdata, out_channel, kernel_size, padding='SAME',\n",
    "                 stride=1, w_init=None, b_init=None,\n",
    "                 use_bias=True, activation=None, data_format='channels_last',\n",
    "                 trainable=True, name=None):\n",
    "        with tf.variable_scope(name):\n",
    "            in_shape = inputdata.get_shape().as_list()\n",
    "            channel_axis = 3 if data_format == 'channels_last' else 1\n",
    "            in_channel = in_shape[channel_axis]\n",
    "            assert in_channel is not None, \"[Deconv2D] Input cannot have unknown channel!\"\n",
    "\n",
    "            padding = padding.upper()\n",
    "\n",
    "            if w_init is None:\n",
    "                w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            if b_init is None:\n",
    "                b_init = tf.constant_initializer()\n",
    "\n",
    "            ret = tf.layers.conv2d_transpose(inputs=inputdata, filters=out_channel,\n",
    "                                             kernel_size=kernel_size,\n",
    "                                             strides=stride, padding=padding,\n",
    "                                             data_format=data_format,\n",
    "                                             activation=activation, use_bias=use_bias,\n",
    "                                             kernel_initializer=w_init,\n",
    "                                             bias_initializer=b_init, trainable=trainable,\n",
    "                                             name=name)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model using conv2d, Relu and Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fcn_decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNDecoder(CNNBaseModel):\n",
    "    def __init__(self, phase):\n",
    "        super(FCNDecoder, self).__init__()\n",
    "\n",
    "    def decode(self, input_tensor_dict, decode_layer_list, name):\n",
    "        ret = dict()\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # score stage 1\n",
    "            input_tensor = input_tensor_dict[decode_layer_list[0]]['data']\n",
    "\n",
    "            score = self.conv2d(inputdata=input_tensor, out_channel=64,\n",
    "                                kernel_size=1, use_bias=False, name='score_origin')\n",
    "            decode_layer_list = decode_layer_list[1:]\n",
    "            for i in range(len(decode_layer_list)):\n",
    "                deconv = self.deconv2d(inputdata=score, out_channel=64, kernel_size=4,\n",
    "                                       stride=2, use_bias=False, name='deconv_{:d}'.format(i + 1))\n",
    "                input_tensor = input_tensor_dict[decode_layer_list[i]]['data']\n",
    "                score = self.conv2d(inputdata=input_tensor, out_channel=64,\n",
    "                                    kernel_size=1, use_bias=False, name='score_{:d}'.format(i + 1))\n",
    "                fused = tf.add(deconv, score, name='fuse_{:d}'.format(i + 1))\n",
    "                score = fused\n",
    "\n",
    "            deconv_final = self.deconv2d(inputdata=score, out_channel=64, kernel_size=16,\n",
    "                                         stride=8, use_bias=False, name='deconv_final')\n",
    "\n",
    "            score_final = self.conv2d(inputdata=deconv_final, out_channel=2,\n",
    "                                      kernel_size=1, use_bias=False, name='score_final')\n",
    "\n",
    "            ret['logits'] = score_final\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vgg_encoder.py\n",
    "https://github.com/machrisaa/tensorflow-vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Encoder(CNNBaseModel):\n",
    "    def __init__(self, phase):\n",
    "        super(VGG16Encoder, self).__init__()\n",
    "        self._train_phase = tf.constant('train', dtype=tf.string)\n",
    "        self._phase = phase\n",
    "        self._is_training = self._init_phase()\n",
    "\n",
    "    def _init_phase(self):\n",
    "        return tf.equal(self._phase, self._train_phase)\n",
    "\n",
    "    def _conv_stage(self, input_tensor, k_size, out_dims, name,\n",
    "                    stride=1, pad='SAME'):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = self.conv2d(inputdata=input_tensor, out_channel=out_dims,\n",
    "                               kernel_size=k_size, stride=stride,\n",
    "                               use_bias=False, padding=pad, name='conv')\n",
    "\n",
    "            bn = self.layerbn(inputdata=conv, is_training=self._is_training, name='bn')\n",
    "\n",
    "            relu = self.relu(inputdata=bn, name='relu')\n",
    "\n",
    "            return relu\n",
    "\n",
    "    def encode(self, input_tensor, name):\n",
    "        ret = OrderedDict()\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # conv stage 1\n",
    "            conv_1_1 = self._conv_stage(input_tensor=input_tensor, k_size=3, out_dims=64, name='conv1_1')\n",
    "            conv_1_2 = self._conv_stage(input_tensor=conv_1_1, k_size=3, out_dims=64, name='conv1_2')\n",
    "            pool1 = self.maxpooling(inputdata=conv_1_2, kernel_size=2, stride=2, name='pool1')\n",
    "\n",
    "            # conv stage 2\n",
    "            conv_2_1 = self._conv_stage(input_tensor=pool1, k_size=3, out_dims=128, name='conv2_1')\n",
    "            conv_2_2 = self._conv_stage(input_tensor=conv_2_1, k_size=3, out_dims=128, name='conv2_2')\n",
    "            pool2 = self.maxpooling(inputdata=conv_2_2, kernel_size=2, stride=2, name='pool2')\n",
    "\n",
    "            # conv stage 3\n",
    "            conv_3_1 = self._conv_stage(input_tensor=pool2, k_size=3, out_dims=256, name='conv3_1')\n",
    "            conv_3_2 = self._conv_stage(input_tensor=conv_3_1, k_size=3, out_dims=256, name='conv3_2')\n",
    "            conv_3_3 = self._conv_stage(input_tensor=conv_3_2, k_size=3, out_dims=256, name='conv3_3')\n",
    "            pool3 = self.maxpooling(inputdata=conv_3_3, kernel_size=2, stride=2, name='pool3')\n",
    "            ret['pool3'] = dict()\n",
    "            ret['pool3']['data'] = pool3\n",
    "            ret['pool3']['shape'] = pool3.get_shape().as_list()\n",
    "\n",
    "            # conv stage 4\n",
    "            conv_4_1 = self._conv_stage(input_tensor=pool3, k_size=3, out_dims=512, name='conv4_1')\n",
    "            conv_4_2 = self._conv_stage(input_tensor=conv_4_1, k_size=3, out_dims=512, name='conv4_2')\n",
    "            conv_4_3 = self._conv_stage(input_tensor=conv_4_2, k_size=3, out_dims=512, name='conv4_3')\n",
    "            pool4 = self.maxpooling(inputdata=conv_4_3, kernel_size=2, stride=2, name='pool4')\n",
    "            ret['pool4'] = dict()\n",
    "            ret['pool4']['data'] = pool4\n",
    "            ret['pool4']['shape'] = pool4.get_shape().as_list()\n",
    "\n",
    "            # conv stage 5\n",
    "            conv_5_1 = self._conv_stage(input_tensor=pool4, k_size=3, out_dims=512, name='conv5_1')\n",
    "            conv_5_2 = self._conv_stage(input_tensor=conv_5_1, k_size=3, out_dims=512, name='conv5_2')\n",
    "            conv_5_3 = self._conv_stage(input_tensor=conv_5_2, k_size=3, out_dims=512, name='conv5_3')\n",
    "            pool5 = self.maxpooling(inputdata=conv_5_3, kernel_size=2, stride=2, name='pool5')\n",
    "            ret['pool5'] = dict()\n",
    "            ret['pool5']['data'] = pool5\n",
    "            ret['pool5']['shape'] = pool5.get_shape().as_list()\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lanenet_merge_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneNet():\n",
    "    def __init__(self, phase):\n",
    "        super(LaneNet, self).__init__()\n",
    "        self._encoder = VGG16Encoder(phase=phase)\n",
    "        self._decoder = FCNDecoder(phase=phase)\n",
    "        return\n",
    "\n",
    "    def _build_model(self, input_tensor, name):\n",
    "        with tf.variable_scope(name):\n",
    "            # first encode\n",
    "            encode_ret = self._encoder.encode(input_tensor=input_tensor,\n",
    "                                              name='encode')\n",
    "            # second decode\n",
    "            decode_ret = self._decoder.decode(input_tensor_dict=encode_ret,\n",
    "                                              name='decode',\n",
    "                                              decode_layer_list=['pool5',\n",
    "                                                                 'pool4',\n",
    "                                                                 'pool3'])\n",
    "            return decode_ret\n",
    "\n",
    "    def compute_loss(self, input_tensor, binary_label, name):\n",
    "        with tf.variable_scope(name):\n",
    "            # Forward propagation to get logits\n",
    "            inference_ret = self._build_model(input_tensor=input_tensor, name='inference')\n",
    "\n",
    "            # Calculate the binary partition loss function\n",
    "            decode_logits = inference_ret['logits']\n",
    "            binary_label_plain = tf.reshape(binary_label,\n",
    "                                            shape=[binary_label.get_shape().as_list()[0] *\n",
    "                                                   binary_label.get_shape().as_list()[1] *\n",
    "                                                   binary_label.get_shape().as_list()[2]])\n",
    "            # Add class weights\n",
    "            unique_labels, unique_id, counts = tf.unique_with_counts(binary_label_plain)\n",
    "            counts = tf.cast(counts, tf.float32)\n",
    "            inverse_weights = tf.divide(1.0,\n",
    "                                        tf.log(tf.add(tf.divide(tf.constant(1.0), counts),\n",
    "                                                      tf.constant(1.02))))\n",
    "            inverse_weights = tf.gather(inverse_weights, binary_label)\n",
    "            binary_segmenatation_loss = tf.losses.sparse_softmax_cross_entropy(labels=binary_label, \\\n",
    "                                                                               logits=decode_logits, \\\n",
    "                                                                               weights=inverse_weights)\n",
    "            binary_segmenatation_loss = tf.reduce_mean(binary_segmenatation_loss)\n",
    "\n",
    "            ret = {'loss': binary_segmenatation_loss, 'binary_seg_logits': decode_logits}\n",
    "\n",
    "            return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cost, optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    input_tensor = tf.placeholder(dtype=tf.float32,\n",
    "                                  shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                         CFG.TRAIN.IMG_WIDTH, 3],\n",
    "                                  name='input_tensor')\n",
    "    binary_label = tf.placeholder(dtype=tf.int64,\n",
    "                                  shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                         CFG.TRAIN.IMG_WIDTH, 1],\n",
    "                                         name='binary_label')\n",
    "\n",
    "    # Create the model\n",
    "    phase = tf.placeholder(dtype=tf.string, shape=None, name='net_phase')\n",
    "    net = LaneNet(phase=phase)\n",
    "\n",
    "    # Define loss\n",
    "    compute_ret = net.compute_loss(input_tensor=input_tensor, binary_label=binary_label, name='lanenet_model')\n",
    "    loss = compute_ret['loss']\n",
    "\n",
    "    # Evaluate model\n",
    "    out_logits = compute_ret['binary_seg_logits']\n",
    "    out_logits = tf.nn.softmax(logits=out_logits)\n",
    "    out_logits_out = tf.argmax(out_logits, axis=-1)\n",
    "    out = tf.argmax(out_logits, axis=-1)\n",
    "    out = tf.expand_dims(out, axis=-1)\n",
    "\n",
    "    idx = tf.where(tf.equal(binary_label, 1))\n",
    "    pix_cls_ret = tf.gather_nd(out, idx)\n",
    "    accuracy = tf.count_nonzero(pix_cls_ret)\n",
    "    accuracy = tf.divide(accuracy, tf.cast(tf.shape(pix_cls_ret)[0], tf.int64))\n",
    "\n",
    "    # Define optimizer\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(CFG.TRAIN.LEARNING_RATE, global_step,\n",
    "                                               100000, 0.1, staircase=True)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \\\n",
    "                                               momentum=CFG.TRAIN.MOMENTUM).minimize(loss=loss,\n",
    "                                                                                     var_list=tf.trainable_variables(),\n",
    "                                                                                     global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sess configuration\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TRAIN.GPU_MEMORY_FRACTION\n",
    "sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "sess = tf.Session(config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tf saver\n",
    "model_save_dir = 'model/tusimple_lanenet'\n",
    "if not ops.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "\n",
    "train_start_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "model_name = 'tusimple_lanenet_{:s}.ckpt'.format(str(train_start_time))\n",
    "model_save_path = ops.join(model_save_dir, model_name)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "tf.train.write_graph(graph_or_graph_def=sess.graph, logdir='',\n",
    "                     name='{:s}/lanenet_model.pb'.format(model_save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tf summary\n",
    "tboard_save_path = 'tboard/tusimple_lanenet_{:s}'.format(str(train_start_time))\n",
    "if not ops.exists(tboard_save_path):\n",
    "    os.makedirs(tboard_save_path)\n",
    "\n",
    "train_accuracy_scalar = tf.summary.scalar(name='train_accuracy', tensor=accuracy)\n",
    "train_loss_scalar = tf.summary.scalar(name='train_loss', tensor=loss)\n",
    "learning_rate_scalar = tf.summary.scalar(name='learning_rate', tensor=learning_rate)\n",
    "merged_summary_op = tf.summary.merge([train_accuracy_scalar, train_loss_scalar, learning_rate_scalar])\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(tboard_save_path)\n",
    "summary_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output image folder\n",
    "image_save_path = 'data_ret/tusimple_lanenet_{:s}'.format(str(train_start_time))\n",
    "if not ops.exists(image_save_path):\n",
    "    os.makedirs(image_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "history = []\n",
    "train_cost_time_mean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_training_data(gt_imgs, binary_gt_labels):\n",
    "    gt_imgs = [cv2.resize(tmp,\n",
    "                          dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "                          dst=tmp,\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "               for tmp in gt_imgs]\n",
    "    gt_imgs = [tmp - VGG_MEAN for tmp in gt_imgs]\n",
    "\n",
    "    binary_gt_labels = [cv2.resize(tmp,\n",
    "                                   dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "                                   dst=tmp,\n",
    "                                   interpolation=cv2.INTER_NEAREST)\n",
    "                        for tmp in binary_gt_labels]\n",
    "    binary_gt_labels = [np.expand_dims(tmp, axis=-1) for tmp in binary_gt_labels]\n",
    "    \n",
    "    return gt_imgs, binary_gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    # sess init or restore\n",
    "    if weights_path is None:\n",
    "        log.info('Training from scratch')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # read vgg model\n",
    "        pretrained_weights = np.load('./data/vgg16.npy', encoding='latin1').item()\n",
    "        for vv in tf.trainable_variables():\n",
    "            weights_key = vv.name.split('/')[-3]\n",
    "            try:\n",
    "                weights = pretrained_weights[weights_key][0]\n",
    "                _op = tf.assign(vv, weights)\n",
    "                sess.run(_op)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    else:\n",
    "        log.info('Restore model from last model checkpoint {:s}'.format(weights_path))\n",
    "        # restore weights\n",
    "        saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "    # epoch loop\n",
    "    for epoch in range(CFG.TRAIN.EPOCHS):\n",
    "\n",
    "        # Use training data for optimization\n",
    "        for _ in range(CFG.TRAIN.NOOFBATCHES):\n",
    "            with tf.device('/cpu:0'):\n",
    "                gt_imgs, binary_gt_labels = train_dataset.next_batch(CFG.TRAIN.BATCH_SIZE)\n",
    "                gt_imgs, binary_gt_labels = resize_training_data(gt_imgs, binary_gt_labels)\n",
    "\n",
    "            sess.run(optimizer, feed_dict={input_tensor:gt_imgs, \n",
    "                                           binary_label:binary_gt_labels, \n",
    "                                           phase:'train'})\n",
    "\n",
    "        # Validate after every epoch\n",
    "        t_start = time.time()\n",
    "        with tf.device('/cpu:0'):\n",
    "            gt_imgs, binary_gt_labels = train_dataset.next_batch(CFG.TRAIN.BATCH_SIZE)\n",
    "            gt_imgs, binary_gt_labels = resize_training_data(gt_imgs, binary_gt_labels)\n",
    "\n",
    "        train_loss, train_accuracy, train_img, train_summary = \\\n",
    "            sess.run([loss, accuracy, out_logits_out, merged_summary_op],\n",
    "                     feed_dict={input_tensor: gt_imgs,\n",
    "                                binary_label: binary_gt_labels,\n",
    "                                phase: 'train'})\n",
    "\n",
    "        # time\n",
    "        cost_time = time.time() - t_start\n",
    "        train_cost_time_mean.append(cost_time)\n",
    "        \n",
    "        # summary\n",
    "        summary_writer.add_summary(summary=train_summary, global_step=epoch)\n",
    "\n",
    "        # history\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES > 10:\n",
    "            history.append([train_loss, train_accuracy])\n",
    "\n",
    "        # progress\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 100 == 0:\n",
    "            print('Epoch: {:6d} loss= {:6f} acc= {:6f} cost_time= {:5f}s '.\n",
    "                  format(epoch, train_loss, train_accuracy, np.mean(train_cost_time_mean)))\n",
    "            train_cost_time_mean.clear()\n",
    "\n",
    "        # output image\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 100 == 0:\n",
    "            binary_seg_image_3ch = np.array([[[0]*3]*__C.TRAIN.IMG_WIDTH]*__C.TRAIN.IMG_HEIGHT, np.float64)\n",
    "            binary_seg_image_3ch[:, :, 0] = 0\n",
    "            binary_seg_image_3ch[:, :, 1] = 0\n",
    "            binary_seg_image_3ch[:, :, 2] = train_img[0][:, :]*255\n",
    "            image = gt_imgs[0] + VGG_MEAN\n",
    "            image_field2 = cv2.addWeighted(image, 1.0, binary_seg_image_3ch, 1.0, 0.0)\n",
    "            path = image_save_path + '/image_{:d}.png'.format(epoch)\n",
    "            cv2.imwrite(path, image_field2)\n",
    "\n",
    "        # store model\n",
    "        if epoch*CFG.TRAIN.NOOFBATCHES % 2000 == 0:\n",
    "            saver.save(sess=sess, save_path=model_save_path, global_step=epoch)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,15),dpi=100)\n",
    "ax1 = fig.add_subplot(2,1,1, facecolor='w')\n",
    "ax1.plot(np.arange(1, history.shape[0] + 1), history[:, 0], label='loss')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.arange(1, history.shape[0] + 1), history[:, 1], label='accuracy', color=cmap(1))\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
